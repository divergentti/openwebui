<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Open WebUI function for Mistral Codestral API use</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Open WebUI function for Mistral Codestral API use</h1>
</header>
<section data-field="subtitle" class="p-summary">
Below is a Python function for Open WebUI that enables you to use Codestral via API (free or paid). Before installation, take a look at…
</section>
<section data-field="body" class="e-content">
<section name="ce34" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="8f98" id="8f98" class="graf graf--h3 graf--leading graf--title">Open WebUI function for Mistral Codestral API use</h3><p name="4f05" id="4f05" class="graf graf--p graf-after--h3">Below is a Python function for Open WebUI that enables you to use Codestral via API (free or paid). Before installation, take a look at Codestral’s capabilities.</p><h3 name="638b" id="638b" class="graf graf--h3 graf-after--p">About Codestral</h3><p name="7289" id="7289" class="graf graf--p graf-after--h3">Regarding to Mistral, limits (<a href="https://console.mistral.ai/limits/" data-href="https://console.mistral.ai/limits/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">link</a>) for the Codestral (<a href="https://console.mistral.ai/codestral" data-href="https://console.mistral.ai/codestral" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">link</a>) are:</p><p name="90b3" id="90b3" class="graf graf--p graf-after--p">Tokens per minute 500,000 tokens and per month 1,000,000,000 tokens.</p><p name="7d33" id="7d33" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Capabilities and Features of a Open-Codestral-Mamba (free)</strong></p><p name="ef3c" id="ef3c" class="graf graf--p graf-after--p">1. Natural Language Understanding:<br> — I can understand and respond to a wide range of queries and topics.<br> — I can generate human-like text based on the input I receive.</p><p name="ad22" id="ad22" class="graf graf--p graf-after--p">2. Multilingual Support:<br> — I can understand and generate responses in multiple languages, including English, Spanish, French, German, Italian, Dutch, Russian, Chinese, Japanese, Korean, Portuguese, Arabic, and Hindi, among others.</p><p name="9703" id="9703" class="graf graf--p graf-after--p">3. Knowledge Base:<br> — I have a broad knowledge base, including information up to 2023.<br> — I can provide explanations, definitions, and summaries on a variety of subjects.</p><p name="059e" id="059e" class="graf graf--p graf-after--p">4. Text Generation:<br> — I can generate coherent and contextually relevant text, such as summaries, translations, and creative writing.<br> — I can help with brainstorming ideas, drafting emails, and writing articles.</p><p name="248b" id="248b" class="graf graf--p graf-after--p">5. Problem-Solving:<br> — I can assist with problem-solving by providing logical steps and explanations.<br> — I can help with mathematical calculations, coding, and other technical problems.</p><p name="c9e9" id="c9e9" class="graf graf--p graf-after--p">6. Engaging Conversations:<br> — I can engage in casual conversations and provide entertaining responses.<br> — I can help with trivia, jokes, and other forms of light-hearted interaction.</p><p name="acf4" id="acf4" class="graf graf--p graf-after--p">7. Educational Support:<br> — I can explain complex concepts in a simple and understandable way.<br> — I can provide study tips, practice problems, and explanations for various subjects.</p><p name="9ddb" id="9ddb" class="graf graf--p graf-after--p">8. Creative Writing:<br> — I can help with writing stories, poems, and other creative pieces.<br> — I can provide feedback and suggestions for improvement.</p><p name="4c25" id="4c25" class="graf graf--p graf-after--p">9. Technical Assistance:<br> — I can help with coding, debugging, and understanding technical concepts.<br> — I can provide guidance on various software tools and platforms.</p><p name="e32d" id="e32d" class="graf graf--p graf-after--p">10. Personal Assistance:<br> — I can help with planning, scheduling, and organizing tasks.<br> — I can provide recommendations for books, movies, and other forms of entertainment.</p><p name="8075" id="8075" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Limitations</strong></p><p name="4e50" id="4e50" class="graf graf--p graf-after--p">While I have many capabilities, it’s important to note that I also have some limitations:</p><ol class="postList"><li name="3fef" id="3fef" class="graf graf--li graf-after--p">Real-Time Information:<br> — I don’t have real-time web browsing capabilities, so my knowledge cutoff is 2023.<br> — I can’t access or interact with the internet.</li></ol><p name="3c1e" id="3c1e" class="graf graf--p graf-after--li">2. Personal Experiences:<br> — I don’t have personal experiences, feelings, or a physical presence.<br> — I can’t browse the internet or access any personal data.</p><p name="2632" id="2632" class="graf graf--p graf-after--p">3. Context Understanding:<br> — While I strive to maintain context in conversations, I might sometimes lose track of context, especially in long or complex discussions.</p><p name="282b" id="282b" class="graf graf--p graf-after--p graf--trailing">4. Ethical Considerations:<br> — I follow ethical guidelines and can’t provide harmful, prejudiced, or illegal information.</p></div></div></section><section name="fb64" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="5b87" id="5b87" class="graf graf--h3 graf--leading">Installation</h3><p name="fd25" id="fd25" class="graf graf--p graf-after--h3">Go to Open WebUI Admin — Functions and create a new function. Name it as you wish, in this example I have just “Codestral”. Then copy and paste my python code to your function.</p><figure name="c4b8" id="c4b8" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*cUSnTXrOBMirX81bvIdEWA.png" data-width="1920" data-height="960" src="https://cdn-images-1.medium.com/max/800/1*cUSnTXrOBMirX81bvIdEWA.png"><figcaption class="imageCaption">Code pasted to new function.</figcaption></figure><p name="236c" id="236c" class="graf graf--p graf-after--figure">Note: the function is also available at OpenWebUI website (<a href="https://openwebui.com/f/hiltsu/mistral_codestral_api_pipe" data-href="https://openwebui.com/f/hiltsu/mistral_codestral_api_pipe" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">link</a>) and from my Github (<a href="https://github.com/divergentti/openwebui/tree/main" data-href="https://github.com/divergentti/openwebui/tree/main" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">link</a>).</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="e8f8" id="e8f8" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-comment"># title: Mistral Codestral Pipe</span><br /><span class="hljs-comment"># authors: Jari Hiltunen</span><br /><span class="hljs-comment"># author_url: https://github.com/divergentti</span><br /><span class="hljs-comment"># version: 0.0.1 (22.01.2025)</span><br /><span class="hljs-comment"># required_open_webui_version: 0.3.17</span><br /><span class="hljs-comment"># license: MIT</span><br /><span class="hljs-comment">#</span><br /><span class="hljs-comment"># Codestral is an open-weight generative AI model explicitly designed for code generation tasks. </span><br /><span class="hljs-comment"># It helps developers write and interact with code through a shared instruction and completion API endpoint.</span><br /><span class="hljs-comment"># As it masters code and English, it can be used to design advanced AI applications for software developers. </span><br /><span class="hljs-comment"># More information at: https://mistral.ai/news/codestral/  </span><br /><span class="hljs-comment"># About limits: https://console.mistral.ai/limits/      </span><br /><span class="hljs-comment"># </span><br /><span class="hljs-comment"># Before using, create your free API-keys at https://console.mistral.ai/codestral  </span><br /><span class="hljs-comment"># After installing this Function, add your API-key to the Valves of the Function (gear rightmost)</span><br /><span class="hljs-keyword">import</span> os<br /><span class="hljs-keyword">import</span> requests<br /><span class="hljs-keyword">import</span> json<br /><span class="hljs-keyword">import</span> time<br /><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Union</span>, Generator, Iterator<br /><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel, Field<br /><span class="hljs-keyword">from</span> open_webui.utils.misc <span class="hljs-keyword">import</span> pop_system_message<br /><br /><br /><span class="hljs-keyword">class</span> <span class="hljs-title class_">Pipe</span>:<br />    <span class="hljs-keyword">class</span> <span class="hljs-title class_">Valves</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br />        CODESTRAL_API_KEY: <span class="hljs-built_in">str</span> = Field(default=<span class="hljs-string">&quot;&quot;</span>)<br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br />        self.debug_stream = <span class="hljs-literal">False</span><br />        self.debug_tokens = <span class="hljs-literal">True</span><br />        self.debug_errors = <span class="hljs-literal">True</span><br />        self.<span class="hljs-built_in">type</span> = <span class="hljs-string">&quot;manifold&quot;</span><br />        self.<span class="hljs-built_in">id</span> = <span class="hljs-string">&quot;codestral&quot;</span><br />        self.name = <span class="hljs-string">&quot;codestral/&quot;</span><br />        self.chat_endpoint = <span class="hljs-string">&quot;https://codestral.mistral.ai/v1/chat/completions&quot;</span><br />        self.temperature = <span class="hljs-number">0.3</span><br />        self.top_p = <span class="hljs-number">0.9</span><br />        self.max_tokens = <span class="hljs-number">4096</span><br />        self.max_tokens_minute = <span class="hljs-number">500000</span>  <span class="hljs-comment"># Tokens per minute</span><br />        self.tokens_left = (<br />            <span class="hljs-number">1000000000</span>  <span class="hljs-comment"># Will be updated from stream, this is max per month</span><br />        )<br />        self.total_tokens_used = <span class="hljs-number">0</span><br />        api_key = os.getenv(<span class="hljs-string">&quot;CODESTRAL_API_KEY&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).strip()<br />        self.valves = self.Valves(CODESTRAL_API_KEY=api_key)<br />        self.last_request_time: <span class="hljs-built_in">float</span> = (Activate your Codestral access <span class="hljs-keyword">from</span> Mistral Dashboard (link) <span class="hljs-keyword">and</span> copy your API-key <span class="hljs-keyword">for</span> the Open WebUI valve (first you create the function, then you add the API-key).<br />            <span class="hljs-number">0.0</span>  <span class="hljs-comment"># Initialize the last request time for rate limiting</span><br />        )<br />        self.rate_limit_reset: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.0</span>  <span class="hljs-comment"># Initialize rate_limit_reset to 0</span><br />        self.rate_limit_interval: <span class="hljs-built_in">float</span> = (<br />            <span class="hljs-number">30.0</span>  <span class="hljs-comment"># Set the rate limit interval in seconds (Open is 100 request per hour)</span><br />        )<br />        self.model_id = <span class="hljs-string">&quot;codestral-latest&quot;</span><br />        self.model_name = <span class="hljs-string">&quot;codestral-4-coders&quot;</span><br />        self.last_token_reset_time = time.time()  <span class="hljs-comment"># Initialize the last token reset time</span><br />        self.tokens_used_this_minute = <span class="hljs-number">0</span>  <span class="hljs-comment"># Initialize tokens used this minute</span><br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">pipes</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">dict</span>]:<br />        <span class="hljs-keyword">try</span>:<br />            <span class="hljs-keyword">return</span> [{<span class="hljs-string">&quot;id&quot;</span>: self.model_id, <span class="hljs-string">&quot;name&quot;</span>: self.model_name}]<br />        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_errors:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Error fetching models: <span class="hljs-subst">{e}</span>&quot;</span>)<br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">pipe</span>(<span class="hljs-params">self, body: <span class="hljs-built_in">dict</span></span>) -&gt; <span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, Generator, Iterator]:<br />        system_message, messages = pop_system_message(body[<span class="hljs-string">&quot;messages&quot;</span>])<br />        processed_messages = []<br />        <span class="hljs-keyword">for</span> message <span class="hljs-keyword">in</span> messages:<br />            processed_content = []<br />            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(message.get(<span class="hljs-string">&quot;content&quot;</span>), <span class="hljs-built_in">list</span>):<br />                <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> message[<span class="hljs-string">&quot;content&quot;</span>]:<br />                    <span class="hljs-keyword">if</span> item[<span class="hljs-string">&quot;type&quot;</span>] == <span class="hljs-string">&quot;text&quot;</span>:<br />                        processed_content.append({<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: item[<span class="hljs-string">&quot;text&quot;</span>]})<br />            <span class="hljs-keyword">else</span>:<br />                processed_content = [<br />                    {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: message.get(<span class="hljs-string">&quot;content&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)}<br />                ]<br />            processed_messages.append(<br />                {<span class="hljs-string">&quot;role&quot;</span>: message[<span class="hljs-string">&quot;role&quot;</span>], <span class="hljs-string">&quot;content&quot;</span>: processed_content}<br />            )<br />        <span class="hljs-comment"># payload is defined as it is at mistral.ai websiteActivate your Codestral access from Mistral Dashboard (link) and copy your API-key for the Open WebUI valve (first you create the function, then you add the API-key).</span><br />        payload = {<br />            <span class="hljs-string">&quot;model&quot;</span>: body[<span class="hljs-string">&quot;model&quot;</span>][body[<span class="hljs-string">&quot;model&quot;</span>].find(<span class="hljs-string">&quot;.&quot;</span>) + <span class="hljs-number">1</span> :],<br />            <span class="hljs-string">&quot;temperature&quot;</span>: body.get(<span class="hljs-string">&quot;temperature&quot;</span>, self.temperature),<br />            <span class="hljs-string">&quot;top_p&quot;</span>: body.get(<span class="hljs-string">&quot;top_p&quot;</span>, self.top_p),<br />            <span class="hljs-string">&quot;max_tokens&quot;</span>: body.get(<span class="hljs-string">&quot;max_tokens&quot;</span>, self.max_tokens),<br />            <span class="hljs-string">&quot;stream&quot;</span>: body.get(<span class="hljs-string">&quot;stream&quot;</span>, <span class="hljs-literal">False</span>),<br />            <span class="hljs-string">&quot;messages&quot;</span>: processed_messages,<br />        }<br />        headers = {<br />            <span class="hljs-string">&quot;Authorization&quot;</span>: <span class="hljs-string">f&quot;Bearer <span class="hljs-subst">{self.valves.CODESTRAL_API_KEY}</span>&quot;</span>,<br />            <span class="hljs-string">&quot;mistral-version&quot;</span>: <span class="hljs-string">&quot;2025-01-01&quot;</span>,<br />            <span class="hljs-string">&quot;Content-Type&quot;</span>: <span class="hljs-string">&quot;application/json&quot;</span>,<br />        }<br />        <span class="hljs-keyword">if</span> self.debug_stream:<br />            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Headers being sent   :&quot;</span>, headers)<br />        <span class="hljs-comment"># Rate limiting</span><br />        current_time = time.time()<br />        elapsed_time: <span class="hljs-built_in">float</span> = current_time - self.last_request_time<br />        <span class="hljs-keyword">if</span> elapsed_time &lt; self.rate_limit_interval:<br />            sleep_time: <span class="hljs-built_in">float</span> = <span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">float</span>(self.rate_limit_reset) - time.time())<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Rate limit exceeded. Sleeping for <span class="hljs-subst">{sleep_time:<span class="hljs-number">.2</span>f}</span> seconds.&quot;</span>)<br />            time.sleep(sleep_time)<br />        self.last_request_time = time.time()<br />        <span class="hljs-keyword">try</span>:<br />            <span class="hljs-keyword">if</span> body.get(<span class="hljs-string">&quot;stream&quot;</span>, <span class="hljs-literal">False</span>):<br />                <span class="hljs-keyword">return</span> self.stream_response(self.chat_endpoint, headers, payload)<br />            <span class="hljs-keyword">else</span>:<br />                <span class="hljs-keyword">return</span> self.non_stream_response(self.chat_endpoint, headers, payload)<br />        <span class="hljs-keyword">except</span> requests.exceptions.RequestException <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Request failed: <span class="hljs-subst">{e}</span>&quot;</span>)<br />            <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;Error: Request failed: <span class="hljs-subst">{e}</span>&quot;</span><br />        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Error in pipe method: <span class="hljs-subst">{e}</span>&quot;</span>)<br />            <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;Error: <span class="hljs-subst">{e}</span>&quot;</span><br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">stream_response</span>(<span class="hljs-params">self, url, headers, payload</span>):<br />        headers[<span class="hljs-string">&quot;Authorization&quot;</span>] = <span class="hljs-string">f&quot;Bearer <span class="hljs-subst">{self.valves.CODESTRAL_API_KEY}</span>&quot;</span><br />        <span class="hljs-keyword">try</span>:<br />            <span class="hljs-keyword">with</span> requests.post(<br />                url, headers=headers, json=payload, stream=<span class="hljs-literal">True</span>, timeout=(<span class="hljs-number">3.05</span>, <span class="hljs-number">60</span>)<br />            ) <span class="hljs-keyword">as</span> response:<br />                <span class="hljs-keyword">if</span> response.status_code != <span class="hljs-number">200</span>:<br />                    <span class="hljs-keyword">raise</span> Exception(<br />                        <span class="hljs-string">f&quot;HTTP Error <span class="hljs-subst">{response.status_code}</span>: <span class="hljs-subst">{response.text}</span>&quot;</span><br />                    )<br />                <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> response.iter_lines():<br />                    <span class="hljs-keyword">if</span> self.debug_stream:<br />                        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Response line: &quot;</span>, line)<br />                    <span class="hljs-keyword">if</span> line:<br />                        line = line.decode(<span class="hljs-string">&quot;utf-8&quot;</span>)<br />                        <span class="hljs-keyword">if</span> line == <span class="hljs-string">&quot;data: [DONE]&quot;</span>:<br />                            <span class="hljs-keyword">if</span> self.debug_stream:<br />                                <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Streaming completed successfully.&quot;</span>)<br />                            <span class="hljs-keyword">break</span><br />                        <span class="hljs-keyword">if</span> line.startswith(<span class="hljs-string">&quot;data: &quot;</span>):<br />                            <span class="hljs-keyword">try</span>:<br />                                data = json.loads(line[<span class="hljs-number">6</span>:])<br />                                <span class="hljs-keyword">if</span> data.get(<span class="hljs-string">&quot;choices&quot;</span>):<br />                                    <span class="hljs-keyword">for</span> choice <span class="hljs-keyword">in</span> data[<span class="hljs-string">&quot;choices&quot;</span>]:<br />                                        <span class="hljs-keyword">if</span> (<br />                                            <span class="hljs-string">&quot;delta&quot;</span> <span class="hljs-keyword">in</span> choice<br />                                            <span class="hljs-keyword">and</span> <span class="hljs-string">&quot;content&quot;</span> <span class="hljs-keyword">in</span> choice[<span class="hljs-string">&quot;delta&quot;</span>]<br />                                        ):<br />                                            <span class="hljs-keyword">yield</span> choice[<span class="hljs-string">&quot;delta&quot;</span>][<span class="hljs-string">&quot;content&quot;</span>]<br />                                        <span class="hljs-keyword">elif</span> (<br />                                            <span class="hljs-string">&quot;finish_reason&quot;</span> <span class="hljs-keyword">in</span> choice<br />                                            <span class="hljs-keyword">and</span> choice[<span class="hljs-string">&quot;finish_reason&quot;</span>] == <span class="hljs-string">&quot;stop&quot;</span><br />                                        ):<br />                                            <span class="hljs-keyword">break</span><br />                                    <span class="hljs-comment"># Extract token usage information</span><br />                                    usage = data.get(<span class="hljs-string">&quot;usage&quot;</span>, {})<br />                                    prompt_tokens = usage.get(<span class="hljs-string">&quot;prompt_tokens&quot;</span>, <span class="hljs-number">0</span>)<br />                                    completion_tokens = usage.get(<br />                                        <span class="hljs-string">&quot;completion_tokens&quot;</span>, <span class="hljs-number">0</span><br />                                    )<br />                                    total_tokens = usage.get(<span class="hljs-string">&quot;total_tokens&quot;</span>, <span class="hljs-number">0</span>)<br />                                    <span class="hljs-comment"># Update total tokens used</span><br />                                    self.total_tokens_used += total_tokens<br />                                    self.tokens_left -= total_tokens<br />                                    <span class="hljs-comment"># Update tokens used this minute</span><br />                                    self.tokens_used_this_minute += total_tokens<br />                                    <span class="hljs-comment"># Check if a minute has passed</span><br />                                    <span class="hljs-keyword">if</span> time.time() - self.last_token_reset_time &gt;= <span class="hljs-number">60</span>:<br />                                        self.tokens_used_this_minute = <span class="hljs-number">0</span><br />                                        self.last_token_reset_time = time.time()<br />                                    <span class="hljs-keyword">if</span> self.debug_tokens <span class="hljs-keyword">and</span> total_tokens &gt; <span class="hljs-number">0</span>:<br />                                        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Prompt Tokens: <span class="hljs-subst">{prompt_tokens}</span>&quot;</span>)<br />                                        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Completion Tokens: <span class="hljs-subst">{completion_tokens}</span>&quot;</span>)<br />                                        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Total Tokens: <span class="hljs-subst">{total_tokens}</span>&quot;</span>)<br />                                        <span class="hljs-built_in">print</span>(<br />                                            <span class="hljs-string">f&quot;Total Tokens Used: <span class="hljs-subst">{self.total_tokens_used}</span>&quot;</span><br />                                        )<br />                                        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Tokens Left: <span class="hljs-subst">{self.tokens_left}</span>&quot;</span>)<br />                                        <span class="hljs-built_in">print</span>(<br />                                            <span class="hljs-string">f&quot;Tokens Used This Minute: <span class="hljs-subst">{self.tokens_used_this_minute}</span>&quot;</span><br />                                        )<br />                                    time.sleep(<br />                                        <span class="hljs-number">0.01</span><br />                                    )  <span class="hljs-comment"># Delay to avoid overwhelming the client</span><br />                            <span class="hljs-keyword">except</span> json.JSONDecodeError:<br />                                <span class="hljs-keyword">if</span> self.debug_stream:<br />                                    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Failed to parse JSON: <span class="hljs-subst">{line}</span>&quot;</span>)<br />                            <span class="hljs-keyword">except</span> KeyError <span class="hljs-keyword">as</span> e:<br />                                <span class="hljs-keyword">if</span> self.debug_stream:<br />                                    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Unexpected data structure: <span class="hljs-subst">{e}</span>&quot;</span>)<br />                                    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Full data: <span class="hljs-subst">{data}</span>&quot;</span>)<br />        <span class="hljs-keyword">except</span> requests.exceptions.RequestException <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Request failed: <span class="hljs-subst">{e}</span>&quot;</span>)<br />            <span class="hljs-keyword">yield</span> <span class="hljs-string">f&quot;Error: Request failed: <span class="hljs-subst">{e}</span>&quot;</span><br />        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;General error in stream_response method: <span class="hljs-subst">{e}</span>&quot;</span>)<br />            <span class="hljs-keyword">yield</span> <span class="hljs-string">f&quot;Error: <span class="hljs-subst">{e}</span>&quot;</span><br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">non_stream_response</span>(<span class="hljs-params">self, url, headers, payload</span>):<br />        headers[<span class="hljs-string">&quot;Authorization&quot;</span>] = <span class="hljs-string">f&quot;Bearer <span class="hljs-subst">{self.valves.CODESTRAL_API_KEY}</span>&quot;</span><br />        <span class="hljs-keyword">try</span>:<br />            response = requests.post(<br />                url, headers=headers, json=payload, timeout=(<span class="hljs-number">3.05</span>, <span class="hljs-number">60</span>)<br />            )<br />            <span class="hljs-keyword">if</span> response.status_code != <span class="hljs-number">200</span>:<br />                <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">f&quot;HTTP Error <span class="hljs-subst">{response.status_code}</span>: <span class="hljs-subst">{response.text}</span>&quot;</span>)<br />            res = response.json()<br />            <span class="hljs-keyword">return</span> (<br />                res[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>][<span class="hljs-string">&quot;content&quot;</span>]<br />                <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;choices&quot;</span> <span class="hljs-keyword">in</span> res <span class="hljs-keyword">and</span> res[<span class="hljs-string">&quot;choices&quot;</span>]<br />                <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;&quot;</span><br />            )<br />        <span class="hljs-keyword">except</span> requests.exceptions.RequestException <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Failed non-stream request: <span class="hljs-subst">{e}</span>&quot;</span>)<br />            <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;Error: <span class="hljs-subst">{e}</span>&quot;</span></span></pre><p name="0d33" id="0d33" class="graf graf--p graf-after--pre">Save the function. Then activate your Codestral access from Mistral Dashboard (<a href="https://console.mistral.ai/codestral" data-href="https://console.mistral.ai/codestral" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">link</a>) and copy your API-key for the Open WebUI valve (gear icon at right).</p><figure name="6c48" id="6c48" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*AMwjhJAeaqD5VVEMI2c7Mw.png" data-width="1907" data-height="600" src="https://cdn-images-1.medium.com/max/800/1*AMwjhJAeaqD5VVEMI2c7Mw.png"><figcaption class="imageCaption">Adding the API-key to the Valve of the function</figcaption></figure><p name="42f2" id="42f2" class="graf graf--p graf-after--figure">Then enable your function (right balloon). Now you should see codestral/codestral-4-coders model in your Models-selection. Now you can start your conversation and have fun.</p><figure name="4e09" id="4e09" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*N1-nrjORJEwewYJz2l9JEA.png" data-width="1518" data-height="948" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*N1-nrjORJEwewYJz2l9JEA.png"></figure><p name="4849" id="4849" class="graf graf--p graf-after--figure">If you like to debug usage, change in the code following debugs:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="0069" id="0069" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"> <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br />        self.debug_stream = <span class="hljs-literal">False</span><br />        self.debug_tokens = <span class="hljs-literal">True</span><br />        self.debug_errors = <span class="hljs-literal">True</span></span></pre><p name="96d0" id="96d0" class="graf graf--p graf-after--pre">As an example, self.debug_tokens = True:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="yaml" name="8d77" id="8d77" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-attr">NFO:</span>     <span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span><span class="hljs-string">:36114</span> <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;GET /api/v1/chats/?page=1 HTTP/1.1&quot;</span> <span class="hljs-number">200</span> <span class="hljs-string">OK</span><br /><span class="hljs-attr">Prompt Tokens:</span> <span class="hljs-number">254</span><br /><span class="hljs-attr">Completion Tokens:</span> <span class="hljs-number">682</span><br /><span class="hljs-attr">Total Tokens:</span> <span class="hljs-number">936</span><br /><span class="hljs-attr">Total Tokens Used:</span> <span class="hljs-number">1164</span><br /><span class="hljs-attr">Tokens Left:</span> <span class="hljs-number">999998836</span><br /><span class="hljs-attr">Tokens Used This Minute:</span> <span class="hljs-number">936</span><br /><span class="hljs-attr">INFO:</span>     <span class="hljs-number">127.0</span><span class="hljs-number">.0</span><span class="hljs-number">.1</span><span class="hljs-string">:57188</span> <span class="hljs-bullet">-</span> <span class="hljs-string">&quot;POST /api/chat/completed HTTP/1.1&quot;</span> <span class="hljs-number">200</span> <span class="hljs-string">OK</span></span></pre><p name="cf8b" id="cf8b" class="graf graf--p graf-after--pre graf--trailing">Enjoy and develop further as you wish!</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@jari.p.hiltunen" class="p-author h-card">Jari Hiltunen</a> on <a href="https://medium.com/p/8072ab8f485d"><time class="dt-published" datetime="2025-01-22T12:58:53.086Z">January 22, 2025</time></a>.</p><p><a href="https://medium.com/@jari.p.hiltunen/open-webui-function-for-mistral-codestral-api-use-8072ab8f485d" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on January 26, 2025.</p></footer></article></body></html>