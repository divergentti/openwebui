<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Running Ollama (LLama 3.2b),</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Running Ollama (LLama 3.2b),</h1>
</header>
<section data-field="subtitle" class="p-summary">
I wanted to test how my old PC with an NVIDIA 1080 Ti performs when I load four backends simultaneously: OpenWebUI, Ollama, Stable…
</section>
<section data-field="body" class="e-content">
<section name="eff1" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="6231" id="6231" class="graf graf--h3 graf--leading graf--title">Running Ollama (LLama 3.2b), Stable Diffusion (Automatic1111), and LibreTranslate on an Old Computer</h3><p name="9cb9" id="9cb9" class="graf graf--p graf-after--h3">I wanted to test how my old PC with an NVIDIA 1080 Ti performs when I load four backends simultaneously: OpenWebUI, Ollama, Stable Diffusion (Automatic1111), and LibreTranslate.</p><p name="2d2a" id="2d2a" class="graf graf--p graf-after--p">To do this test, I created a picture first, then asked the response to be translated into Finnish. During the generation process, I used the <code class="markup--code markup--p-code">nvidia-smi</code> command to monitor GPU utilization.</p><p name="c6c0" id="c6c0" class="graf graf--p graf-after--p">For the Automatic1111 startup I used parameters optimized for medium VRAM GPU:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="css" name="2fc2" id="2fc2" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"> <span class="hljs-attr">--opt-split-attention</span> <span class="hljs-attr">--medvram</span> <span class="hljs-attr">--xformers</span> <span class="hljs-attr">--no-half-vae</span> <span class="hljs-attr">--api</span> <span class="hljs-attr">--listen</span></span></pre><p name="e084" id="e084" class="graf graf--p graf-after--pre">For the OpenWebUI I used parameters:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="bash" name="d2cb" id="d2cb" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-built_in">export</span> USE_CUDA_DOCKER=True<br /><span class="hljs-built_in">export</span> ENABLE_IMAGE_GENERATION=True<br /><span class="hljs-built_in">export</span> PDF_EXTRACT_IMAGES=True</span></pre><p name="0614" id="0614" class="graf graf--p graf-after--pre">In the <strong class="markup--strong markup--p-strong">OpenWebUI</strong> settings page for <strong class="markup--strong markup--p-strong">Automatic1111</strong>, I specified the <strong class="markup--strong markup--p-strong">Turbo SDXL</strong> model, with the sample type set to <strong class="markup--strong markup--p-strong">DPM++ SDE</strong>, the scheduler configured as <strong class="markup--strong markup--p-strong">Karras</strong>, a <strong class="markup--strong markup--p-strong">CFG scale</strong> of 2, and a resolution of <strong class="markup--strong markup--p-strong">1024x1024</strong>.</p><ul class="postList"><li name="d7b1" id="d7b1" class="graf graf--li graf-after--p">The <strong class="markup--strong markup--li-strong">DPM++ SDE</strong> (Denoising Probabilistic Model with Stochastic Differential Equations) sampler is a diffusion-based model that provides more stable and high-quality image generation, especially useful for complex scenes.</li><li name="a624" id="a624" class="graf graf--li graf-after--li">The <strong class="markup--strong markup--li-strong">Karras scheduler</strong> is known for its smooth noise scheduling, improving the quality and consistency of outputs across steps.</li><li name="ff41" id="ff41" class="graf graf--li graf-after--li">The <strong class="markup--strong markup--li-strong">CFG scale</strong> (Classifier-Free Guidance scale) controls the trade-off between adhering to the text prompt and generating diverse outputs, with a lower value (like 2) typically offering more creative freedom but less strict adherence to the prompt.</li></ul><p name="f4c5" id="f4c5" class="graf graf--p graf-after--li">With <strong class="markup--strong markup--p-strong">Turbo</strong> and <strong class="markup--strong markup--p-strong">Lightning</strong> modes enabled, which accelerate the diffusion process, just <strong class="markup--strong markup--p-strong">6 sampling steps</strong> are sufficient for generating high-quality images, greatly reducing processing time while maintaining output fidelity.</p><figure name="fe58" id="fe58" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*3DUAhxXPeEjphi8o0wD4NQ.png" data-width="918" data-height="855" src="https://cdn-images-1.medium.com/max/800/1*3DUAhxXPeEjphi8o0wD4NQ.png"></figure><p name="16f1" id="16f1" class="graf graf--p graf-after--figure">The LibreTranslate startup was simply:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="bash" name="5c93" id="5c93" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-built_in">source</span> venv/bin/activate<br />libretranslate</span></pre><p name="4b78" id="4b78" class="graf graf--p graf-after--pre">Prompt for the image generation was:</p><blockquote name="f773" id="f773" class="graf graf--pullquote graf-after--p">Make me image of a witch (blond, red eyes, leather clothing, diamonds, earrings) holding a burning (firemode) iceball. Golden ratio, insane details, masterpiece, 35mm photography, dslr, kodachrome, 8k, hdr, vivid and vibrant colors, reflections.</blockquote><figure name="8356" id="8356" class="graf graf--figure graf-after--pullquote"><img class="graf-image" data-image-id="1*WQBFPNP1pfEFfDs4oraQQg.png" data-width="1152" data-height="909" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*WQBFPNP1pfEFfDs4oraQQg.png"><figcaption class="imageCaption">Image generation with OpenWebUI</figcaption></figure><p name="070d" id="070d" class="graf graf--p graf-after--figure">LLama 3.2b response was:</p><blockquote name="109d" id="109d" class="graf graf--blockquote graf-after--p"><strong class="markup--strong markup--blockquote-strong">Image Generation Successful</strong></blockquote><blockquote name="e267" id="e267" class="graf graf--blockquote graf-after--blockquote">Your image of a witch has been successfully generated.</blockquote><blockquote name="8e5d" id="8e5d" class="graf graf--blockquote graf-after--blockquote">A mesmerizing figure emerges from the shadows, clad in sleek leather attire adorned with glinting diamonds and intricate earrings that seem to shimmer in the flickering light. Her raven tresses cascade down her back like a waterfall of night, framing an ethereal visage with piercing red eyes that burn like hot coals.</blockquote><blockquote name="f167" id="f167" class="graf graf--blockquote graf-after--blockquote">In one hand, she grasps a blazing iceball, its icy surface reflecting the vibrant hues of the surrounding environment like a kaleidoscope of colors. The golden ratio governs the composition, imbuing the image with a sense of balance and harmony that belies the fantastical elements at play.</blockquote><blockquote name="9591" id="9591" class="graf graf--blockquote graf-after--blockquote">The camera captures the scene in stunning 35mm photography, evoking the classic aesthetic of DSLRs and the timeless allure of Kodachrome film stock. As the light catches the subject’s features, it transforms her into a living, breathing masterpiece — a true work of art that defies the boundaries of reality.</blockquote><blockquote name="8699" id="8699" class="graf graf--blockquote graf-after--blockquote">In HDR, every detail is amplified, casting no shadows and rendering the image in resplendent 8K clarity. Vibrant colors dance across the frame, imbuing the witch’s world with an otherworldly aura that seems to pulse with life.</blockquote><blockquote name="16bd" id="16bd" class="graf graf--blockquote graf-after--blockquote">As the light dances across her reflection, it creates a dazzling display of color and texture, as if the very fabric of reality is being manipulated by the witch’s presence. It’s an image that will leave you breathless, a true tour de force of visual artistry that will haunt your dreams long after the moment has passed.</blockquote><p name="1d84" id="1d84" class="graf graf--p graf-after--blockquote">Then I clicked Multitranslate button:</p><blockquote name="7796" id="7796" class="graf graf--blockquote graf-after--p">— — — Translated to: fi language — — — !</blockquote><blockquote name="6901" id="6901" class="graf graf--blockquote graf-after--blockquote">[muokkaa | muokkaa wikitekstiä] (/cache/image/generations/c6748cbbb-1eb6–434d-93f1–888033e93124.png) ***Image Generation Successful</blockquote><blockquote name="2250" id="2250" class="graf graf--blockquote graf-after--blockquote">Kuvasi noidasta on tuotettu onnistuneesti.</blockquote><blockquote name="8ee6" id="8ee6" class="graf graf--blockquote graf-after--blockquote">Mesmerointihahmo nousee varjoista, tahraa sleekissä nahkapuvussa, joka on koristeltu kirkastavilla timanteilla ja monimutkaisilla korvakorvikkeilla, jotka näyttävät paistavan valossa. Hänen kosteat tressinsä kaskeroivat hänen selkänsä kuin yön vesiputouksen, kehystäen eteerisen visagen lävistys punaiset silmät, jotka polttavat kuin kuumat hiilet.</blockquote><blockquote name="fdfc" id="fdfc" class="graf graf--blockquote graf-after--blockquote">Yhdessä kädessä hän tarttuu vilkkaaseen jääpalloon, sen jääiseen pintaan, joka heijastaa ympäröivän ympäristön elinvoimaisia sävyjä, kuten värien kaleidoskooppia. Kultainen suhde hallitsee koostumusta, kuvan imbuoiminen tasapainon ja harmonian tunteella, joka uskoo pelin fantastisiin elementteihin.</blockquote><blockquote name="c00a" id="c00a" class="graf graf--blockquote graf-after--blockquote">Kamera vangitsee näyttämön upeassa 35mm:n valokuvauksessa, herättää DSLR:n klassisen estetiikan ja Kodachromen elokuvakannan ajattoman houkutuksen. Kun valo tarttuu aiheen ominaisuuksiin, se muuntaa hänet eläväksi, hengittäväksi mestariteokseksi — todelliseksi taideteokseksi, joka täyttää todellisuuden rajat.</blockquote><blockquote name="e497" id="e497" class="graf graf--blockquote graf-after--blockquote">HDR:ssä kaikki yksityiskohdat ovat vahvistuneet, ei varjoja ja kuvan muuttaminen 8K:n selkeydellä. Vibrant värit tanssivat kehyksen yli, jäljittelemällä noidan maailmaa toisella tavalla auralla, joka tuntuu pulssivan elämää.</blockquote><blockquote name="041f" id="041f" class="graf graf--blockquote graf-after--blockquote graf--trailing">Kun valo tanssii hänen heijastuksensa yli, se luo häikäisevän väri- ja tekstuurinäytön, ikään kuin noidan läsnäolo manipuloi todellisuutta. Se on kuva, joka jättää sinut hengittämättömäksi, todellinen visuaalisen taiteen kiertue, joka kummittelee unelmiasi kauan sen jälkeen, kun se on ohi.</blockquote></div></div></section><section name="ab76" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="098c" id="098c" class="graf graf--h3 graf--leading">GPU utilization and memory usage</h3><p name="4d36" id="4d36" class="graf graf--p graf-after--h3">During image generation GPU utilization was at peak, but LibreTranslate was so fast, that I did not catch how much it caused GPU utilization while translated.</p><figure name="8bca" id="8bca" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*p91RiJqVYKWAxohdIWlSUQ.png" data-width="1161" data-height="552" src="https://cdn-images-1.medium.com/max/800/1*p91RiJqVYKWAxohdIWlSUQ.png"><figcaption class="imageCaption">nvidia-smi (GPU utilization) during image generation</figcaption></figure><p name="74e0" id="74e0" class="graf graf--p graf-after--figure">Ollama (ollama ps) seems to use 4GB for llama3.2b and 1GB for paraphrase-multilingual during imeage generation:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="vbnet" name="3290" id="3290" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">NAME ID SIZE PROCESSOR <span class="hljs-keyword">UNTIL</span> <br />llama3.<span class="hljs-number">2</span>:<span class="hljs-number">3</span>b a80c4f17acd5 <span class="hljs-number">4.0</span> GB <span class="hljs-number">100%</span> GPU <span class="hljs-number">4</span> minutes <span class="hljs-keyword">from</span> now <br />paraphrase-multilingual:latest ba13c2e06707 <span class="hljs-number">1.0</span> GB <span class="hljs-number">100%</span> GPU <span class="hljs-number">4</span> minutes <span class="hljs-keyword">from</span> now</span></pre><p name="2c34" id="2c34" class="graf graf--p graf-after--pre graf--trailing">I didn’t encounter any <strong class="markup--strong markup--p-strong">CUDA Out Of Memory</strong> errors during this test, which suggests that older gaming PCs can handle relatively complex setups like this. Even better, if you have multiple older PCs with <strong class="markup--strong markup--p-strong">Nvidia 1080Ti</strong> GPUs, you can distribute them across your LAN, with each acting as a server to provide subservices for <strong class="markup--strong markup--p-strong">OpenWebUI</strong>.</p></div></div></section><section name="c9f3" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="4630" id="4630" class="graf graf--h3 graf--leading">Internet connections for LLM, translate and image generations</h3><p name="2b15" id="2b15" class="graf graf--p graf-after--h3">Locally installed translators and LLMs are an excellent choice, provided they can be configured to neither send nor receive data over the internet. Servers can operate within the same subnet (LAN) or VLANs, completely isolated from the internet.</p><p name="a20c" id="a20c" class="graf graf--p graf-after--p">If you use multiple servers in your LAN for applications like Stable Diffusion, you can switch between them by adjusting server addresses and ports as needed.</p><p name="f2fd" id="f2fd" class="graf graf--p graf-after--p">To ensure that everything runs locally without any internet communication, I closed all programs and physically disconnected the Ethernet cable from my old PC. All backends started normally.</p><figure name="8c03" id="8c03" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*YuPyf1A6NPC6f1nfRxLiIw.png" data-width="656" data-height="934" src="https://cdn-images-1.medium.com/max/800/1*YuPyf1A6NPC6f1nfRxLiIw.png"><figcaption class="imageCaption">Automatic1111, OpenWebUI and LibreTranslate backends</figcaption></figure><p name="7ddf" id="7ddf" class="graf graf--p graf-after--figure">Monitoring network activity with <strong class="markup--strong markup--p-strong">iftop</strong> showed nothing, as expected, since the Ethernet cable was disconnected.</p><figure name="f3ce" id="f3ce" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*Qph_mJ7a6ROsK_DgkdvYOQ.png" data-width="1153" data-height="474" src="https://cdn-images-1.medium.com/max/800/1*Qph_mJ7a6ROsK_DgkdvYOQ.png"><figcaption class="imageCaption">iftop command, no connections</figcaption></figure><p name="b989" id="b989" class="graf graf--p graf-after--figure">Similarly, translation did not try to connect to any Internet addresses:</p><figure name="0c03" id="0c03" class="graf graf--figure graf-after--p graf--trailing"><img class="graf-image" data-image-id="1*VA2zkSRG4kvTms0HLOLQ1g.png" data-width="1122" data-height="624" src="https://cdn-images-1.medium.com/max/800/1*VA2zkSRG4kvTms0HLOLQ1g.png"><figcaption class="imageCaption">iftop during translation</figcaption></figure></div></div></section><section name="8345" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="e4cf" id="e4cf" class="graf graf--h3 graf--leading">Summary</h3><p name="cd8d" id="cd8d" class="graf graf--p graf-after--h3">You can run <strong class="markup--strong markup--p-strong">Ollama</strong>, <strong class="markup--strong markup--p-strong">Stable Diffusion</strong>, <strong class="markup--strong markup--p-strong">LibreTranslate</strong>, and <strong class="markup--strong markup--p-strong">OpenWebUI</strong> on an older PC, but whether this is the best option depends on your needs. While older hardware can handle these tasks, it might be less efficient compared to more modern systems, especially when running resource-intensive applications like <strong class="markup--strong markup--p-strong">Stable Diffusion</strong>. Using the <strong class="markup--strong markup--p-strong">Automatic1111</strong> frontend for Stable Diffusion, for example, offers far more flexibility with additional parameters and options, allowing for more efficient performance on capable machines.</p><p name="1ee6" id="1ee6" class="graf graf--p graf-after--p">In a business or home environment, where multiple users want<strong class="markup--strong markup--p-strong"><em class="markup--em markup--p-em"> secure, offline access</em></strong> without internet connectivity, running such services locally through <strong class="markup--strong markup--p-strong">OpenWebUI</strong> can be a very viable solution. Scenarios where this setup makes sense include:</p><ol class="postList"><li name="3a0b" id="3a0b" class="graf graf--li graf-after--p"><strong class="markup--strong markup--li-strong">Privacy and Security Concerns</strong>: Sensitive data can be processed entirely on local machines, without exposing anything to the cloud or external servers, which is critical for businesses handling proprietary or confidential information.</li><li name="d1d1" id="d1d1" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Cost-Effectiveness</strong>: Utilizing older PCs with <strong class="markup--strong markup--li-strong">Nvidia 1080Ti GPUs</strong> or similar hardware can be a cost-effective solution, particularly for small businesses or individuals who cannot invest in cloud services or newer hardware.</li><li name="d65a" id="d65a" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Distributed Setup for Efficiency</strong>: If you have multiple older PCs with GPUs, you can distribute workloads across your local network. Each PC can act as a server, handling specific tasks like running <strong class="markup--strong markup--li-strong">Stable Diffusion</strong>, <strong class="markup--strong markup--li-strong">LibreTranslate</strong>, or other LLM-based services, thereby optimizing performance without upgrading hardware.</li><li name="f08e" id="f08e" class="graf graf--li graf-after--li"><strong class="markup--strong markup--li-strong">Offline Availability</strong>: In situations where reliable internet connectivity is not guaranteed or where full offline functionality is required (e.g., remote locations or highly secure environments), locally running these tools ensures uninterrupted access to machine learning models and translation services.</li></ol><p name="1dd2" id="1dd2" class="graf graf--p graf-after--li">While this setup may not be the most powerful, it can still be a practical and secure solution, especially when combined with a well-structured <strong class="markup--strong markup--p-strong">LAN</strong> to distribute the workload.</p><figure name="9513" id="9513" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*eBdu_4du9RhT77IZPT-Giw.png" data-width="1024" data-height="1024" src="https://cdn-images-1.medium.com/max/800/1*eBdu_4du9RhT77IZPT-Giw.png"><figcaption class="imageCaption">Test #2 picture</figcaption></figure><figure name="6019" id="6019" class="graf graf--figure graf-after--figure graf--trailing"><img class="graf-image" data-image-id="1*hAVn2ckN2n5lKPj0jlSdSQ.png" data-width="1024" data-height="1024" src="https://cdn-images-1.medium.com/max/800/1*hAVn2ckN2n5lKPj0jlSdSQ.png"><figcaption class="imageCaption">Test #3 picture</figcaption></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@jari.p.hiltunen" class="p-author h-card">Jari Hiltunen</a> on <a href="https://medium.com/p/982f7fb7e6f5"><time class="dt-published" datetime="2024-10-13T12:10:18.501Z">October 13, 2024</time></a>.</p><p><a href="https://medium.com/@jari.p.hiltunen/running-ollama-llama-3-2b-982f7fb7e6f5" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on January 26, 2025.</p></footer></article></body></html>