Open WebUI: Text to Speech

If you’d like to convert the text generated by Open WebUI into speech, the default Text-to-Speech (TTS) implementation (via WebAPI) can sound quite rudimentary. TTS is a technology that synthesizes natural-sounding speech from text, and its quality can vary greatly depending on the model and method used.

To achieve significantly better speech quality, especially if you have a GPU capable of running transformer models, you can switch to a transformer-based TTS system like SpeechT5 or similar models available via Hugging Face. These produce much more natural and expressive speech.

Alternatively, if you have access to premium services like OpenAI, ElevenLabs, or Azure AI Speech, you can integrate them to generate state-of-the-art, lifelike voices. These services typically offer support for multiple languages and customizable voices, making them an excellent choice for high-quality speech synthesis.

If you like to experiment local transformer speech, go to the OI Admin — Settings — Audio select Text-to-Speech Engine Transformers (local). Open WebUI use Microsoft’s SpeechT5 (link) as a TTS engine. First time you use SpeechT5 transformers TTS, your backend downloands pytorch_models:


config.json: 100%|█████████████████████████| 2.06k/2.06k [00:00<00:00, 8.31MB/s]
pytorch_model.bin: 100%|█████████████████████| 585M/585M [00:17<00:00, 33.6MB/s]
tokenizer_config.json: 100%|████████████████████| 232/232 [00:00<00:00, 803kB/s]
spm_char.model: 100%|████████████████████████| 238k/238k [00:00<00:00, 5.23MB/s]
added_tokens.json: 100%|██████████████████████| 40.0/40.0 [00:00<00:00, 142kB/s]
special_tokens_map.json: 100%|██████████████████| 234/234 [00:00<00:00, 478kB/s]
preprocessor_config.json: 100%|████████████████| 433/433 [00:00<00:00, 3.38MB/s]
Device set to use cuda:0:   0%|                       | 0.00/433 [00:00<?, ?B/s]
config.json: 100%|█████████████████████████████| 636/636 [00:00<00:00, 3.83MB/s]
pytorch_model.bin: 100%|███████████████████| 50.7M/50.7M [00:02<00:00, 18.7MB/s]
README.md: 100%|███████████████████████████| 1.01k/1.01k [00:00<00:00, 2.39MB/s]
cmu-arctic-xvectors.py: 100%|██████████████| 1.36k/1.36k [00:00<00:00, 4.59MB/s]
0000.parquet: 100%|████████████████████████| 21.3M/21.3M [00:01<00:00, 15.5MB/s]
Generating validation split: 100%|█| 7931/7931 [00:00<00:00, 72916.04 examples/s
model.safetensors: 100%|███████████████████| 50.6M/50.6M [00:03<00:00, 15.0MB/s]
model.safetensors:  43%|█████████            | 252M/585M [00:11<00:17, 19.5MB/s]INFO:     connection closed

Microsoft’s SpeechT5 is as default English only. In this example you hear how Finnish words in between text are spoken:

Changing the language isn’t a straightforward task and typically involves tweaking the Open WebUI frontend code, which isn’t generally recommended. However, if you’re determined to make this adjustment, you can start by exploring where Hugging Face and PyTorch store their default models — ~/.cache/huggingface/ for Hugging Face and ~/.cache/torch/ for PyTorch. For example, a Microsoft TTS model might be located at:

.cache/huggingface/hub/models--microsoft--speecht5_tts

Then you integrate your language, like for Finnish crcdng/speecht5_finetuned_voxpopuli_fi (link) and add secondary language, like:

from transformers import SpeechT5Processor, SpeechT5ForTextToSpeech
import torch

# Load Finnish model and processor
processor_fi = SpeechT5Processor.from_pretrained("crcdng/speecht5_finetuned_voxpopuli_fi")
model_fi = SpeechT5ForTextToSpeech.from_pretrained("crcdng/speecht5_finetuned_voxpopuli_fi")
