<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Open WebUI: Text to Speech</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Open WebUI: Text to Speech</h1>
</header>
<section data-field="subtitle" class="p-summary">
If you’d like to convert the text generated by Open WebUI into speech, the default Text-to-Speech (TTS) implementation (via WebAPI) can…
</section>
<section data-field="body" class="e-content">
<section name="5388" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="5bd0" id="5bd0" class="graf graf--h3 graf--leading graf--title">Open WebUI: Text to Speech</h3><p name="6e0e" id="6e0e" class="graf graf--p graf-after--h3">If you’d like to convert the text generated by Open WebUI into speech, the default Text-to-Speech (TTS) implementation (via WebAPI) can sound quite rudimentary. TTS is a technology that synthesizes natural-sounding speech from text, and its quality can vary greatly depending on the model and method used.</p><p name="1e70" id="1e70" class="graf graf--p graf-after--p">To achieve significantly better speech quality, especially if you have a GPU capable of running transformer models, you can switch to a transformer-based TTS system like SpeechT5 or similar models available via Hugging Face. These produce much more natural and expressive speech.</p><p name="e473" id="e473" class="graf graf--p graf-after--p">Alternatively, if you have access to premium services like OpenAI, ElevenLabs, or Azure AI Speech, you can integrate them to generate state-of-the-art, lifelike voices. These services typically offer support for multiple languages and customizable voices, making them an excellent choice for high-quality speech synthesis.</p><p name="3ad5" id="3ad5" class="graf graf--p graf-after--p">If you like to experiment local transformer speech, go to the OI Admin — Settings — Audio select Text-to-Speech Engine Transformers (local). Open WebUI use Microsoft’s SpeechT5 (<a href="https://huggingface.co/microsoft/speecht5_tts" data-href="https://huggingface.co/microsoft/speecht5_tts" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">link</a>) as a TTS engine. First time you use SpeechT5 transformers TTS, your backend downloands pytorch_models:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="bash" name="6566" id="6566" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><br />config.json: 100%|█████████████████████████| 2.06k/2.06k [00:00&lt;00:00, 8.31MB/s]<br />pytorch_model.bin: 100%|█████████████████████| 585M/585M [00:17&lt;00:00, 33.6MB/s]<br />tokenizer_config.json: 100%|████████████████████| 232/232 [00:00&lt;00:00, 803kB/s]<br />spm_char.model: 100%|████████████████████████| 238k/238k [00:00&lt;00:00, 5.23MB/s]<br />added_tokens.json: 100%|██████████████████████| 40.0/40.0 [00:00&lt;00:00, 142kB/s]<br />special_tokens_map.json: 100%|██████████████████| 234/234 [00:00&lt;00:00, 478kB/s]<br />preprocessor_config.json: 100%|████████████████| 433/433 [00:00&lt;00:00, 3.38MB/s]<br />Device <span class="hljs-built_in">set</span> to use cuda:0:   0%|                       | 0.00/433 [00:00&lt;?, ?B/s]<br />config.json: 100%|█████████████████████████████| 636/636 [00:00&lt;00:00, 3.83MB/s]<br />pytorch_model.bin: 100%|███████████████████| 50.7M/50.7M [00:02&lt;00:00, 18.7MB/s]<br />README.md: 100%|███████████████████████████| 1.01k/1.01k [00:00&lt;00:00, 2.39MB/s]<br />cmu-arctic-xvectors.py: 100%|██████████████| 1.36k/1.36k [00:00&lt;00:00, 4.59MB/s]<br />0000.parquet: 100%|████████████████████████| 21.3M/21.3M [00:01&lt;00:00, 15.5MB/s]<br />Generating validation <span class="hljs-built_in">split</span>: 100%|█| 7931/7931 [00:00&lt;00:00, 72916.04 examples/s<br />model.safetensors: 100%|███████████████████| 50.6M/50.6M [00:03&lt;00:00, 15.0MB/s]<br />model.safetensors:  43%|█████████            | 252M/585M [00:11&lt;00:17, 19.5MB/s]INFO:     connection closed</span></pre><p name="06c5" id="06c5" class="graf graf--p graf-after--pre">Microsoft’s SpeechT5 is as default English only. In this example you hear how Finnish words in between text are spoken:</p><figure name="7a50" id="7a50" class="graf graf--figure graf--iframe graf-after--p graf--trailing"><iframe src="https://www.youtube.com/embed/vBJof7u6IhM?feature=oembed" width="640" height="480" frameborder="0" scrolling="no"></iframe></figure></div></div></section><section name="c2af" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><figure name="0a96" id="0a96" class="graf graf--figure graf--leading"><img class="graf-image" data-image-id="1*IsucL5q1u9YCqkpuIUuyjQ.jpeg" data-width="1024" data-height="768" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*IsucL5q1u9YCqkpuIUuyjQ.jpeg"></figure><p name="f2e4" id="f2e4" class="graf graf--p graf-after--figure">Changing the language isn’t a straightforward task and typically involves tweaking the Open WebUI frontend code, which isn’t generally recommended. However, if you’re determined to make this adjustment, you can start by exploring where Hugging Face and PyTorch store their default models — <code class="markup--code markup--p-code">~/.cache/huggingface/</code> for Hugging Face and <code class="markup--code markup--p-code">~/.cache/torch/</code> for PyTorch. For example, a Microsoft TTS model might be located at:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="bash" name="b81d" id="b81d" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">.cache/huggingface/hub/models--microsoft--speecht5_tts</span></pre><p name="07a2" id="07a2" class="graf graf--p graf-after--pre">Then you integrate your language, like for Finnish crcdng/speecht5_finetuned_voxpopuli_fi (<a href="https://huggingface.co/crcdng/speecht5_finetuned_voxpopuli_fi" data-href="https://huggingface.co/crcdng/speecht5_finetuned_voxpopuli_fi" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">link</a>) and add secondary language, like:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="python" name="4fe5" id="4fe5" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-keyword">from</span> transformers <span class="hljs-keyword">import</span> SpeechT5Processor, SpeechT5ForTextToSpeech<br /><span class="hljs-keyword">import</span> torch<br /><br /><span class="hljs-comment"># Load Finnish model and processor</span><br />processor_fi = SpeechT5Processor.from_pretrained(<span class="hljs-string">&quot;crcdng/speecht5_finetuned_voxpopuli_fi&quot;</span>)<br />model_fi = SpeechT5ForTextToSpeech.from_pretrained(<span class="hljs-string">&quot;crcdng/speecht5_finetuned_voxpopuli_fi&quot;</span>)</span></pre><p name="c5e6" id="c5e6" class="graf graf--p graf-after--pre graf--trailing"><strong class="markup--strong markup--p-strong">Happy coding!</strong></p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@jari.p.hiltunen" class="p-author h-card">Jari Hiltunen</a> on <a href="https://medium.com/p/28bfb6033853"><time class="dt-published" datetime="2025-01-24T11:52:25.639Z">January 24, 2025</time></a>.</p><p><a href="https://medium.com/@jari.p.hiltunen/open-webui-text-to-speech-28bfb6033853" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on January 26, 2025.</p></footer></article></body></html>
