<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Debugging Mistral.ai API issue with Open WebUI: giving up</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Debugging Mistral.ai API issue with Open WebUI: giving up</h1>
</header>
<section data-field="subtitle" class="p-summary">
Example how to create a function to Open WebUI
</section>
<section data-field="body" class="e-content">
<section name="4c14" class="section section--body section--first"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="42e1" id="42e1" class="graf graf--h3 graf--leading graf--title">Debugging Mistral.ai API issue with Open WebUI : giving up</h3><p name="ebfc" id="ebfc" class="graf graf--p graf-after--h3">Someone has already created a function for Open WebUI and Mistral. You can download it here (<a href="https://openwebui.com/f/robsonlvr76/mistral_api" data-href="https://openwebui.com/f/robsonlvr76/mistral_api" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">link</a>). However, I run into following problem with that script:</p><figure name="2126" id="2126" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*B8R7XEVdW7VFgzkbHz2FDg.png" data-width="1343" data-height="540" src="https://cdn-images-1.medium.com/max/800/1*B8R7XEVdW7VFgzkbHz2FDg.png"><figcaption class="imageCaption">Function published at OpenWebUI site</figcaption></figure><p name="610e" id="610e" class="graf graf--p graf-after--figure">I tried to create a better script, which seems to work quite well for the chat. However, since Mistral.ai lists their models multiple times with different versions, cleaning up the model lists becomes a little bit complicated.</p><p name="d751" id="d751" class="graf graf--p graf-after--p">My function is available for your testing and further development here (<a href="https://openwebui.com/f/hiltsu/mistral_api_manifold" data-href="https://openwebui.com/f/hiltsu/mistral_api_manifold" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">link</a>) and below. With my draft function, I get:</p><figure name="e22b" id="e22b" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*fpOXnnus6ZcffU3s74hq7g.png" data-width="1364" data-height="666" src="https://cdn-images-1.medium.com/max/800/1*fpOXnnus6ZcffU3s74hq7g.png"><figcaption class="imageCaption">Function draft below — result window</figcaption></figure><p name="3600" id="3600" class="graf graf--p graf-after--figure graf--trailing">The Mistral chat is working fine via Open WebUI, but from the Mistral La Plateforme (<a href="https://console.mistral.ai/usage/" data-href="https://console.mistral.ai/usage/" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">link</a>) I do not see any increasing API key usage. This is most likely because Free plan does not increase API-usage counters (I am not sure about this). The backend shows that it handshakes with Mistral with proper API-keys and payload is ok, and shows consumed tokens.</p></div></div></section><section name="c31e" class="section section--body"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="1d6c" id="1d6c" class="graf graf--h3 graf--leading">Testing the API function for Mistral.ai</h3><p name="124f" id="124f" class="graf graf--p graf-after--h3">Note! If you develop functions, they are stored in the Open WebUI database! <strong class="markup--strong markup--p-strong">It is highly advisable to backup your Open WebUI installation</strong> before you test your own functions! At least keep OI open twice so that in other window you have function open and other window you have chat screen open. In case you end up to situation that OI chat part does not work, you can fix your Function before you loose your connectivity to the backend due to malfunctioning Function code!</p><figure name="5556" id="5556" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*c6Jkz0_Cf888mo99swX-rw.png" data-width="1914" data-height="686" src="https://cdn-images-1.medium.com/max/800/1*c6Jkz0_Cf888mo99swX-rw.png"><figcaption class="imageCaption">Left is Mistral API Function, right is a chat with Mistral Nemo</figcaption></figure><p name="ecc4" id="ecc4" class="graf graf--p graf-after--figure">First, disable from connections the Mistral.ai (OpenAI) connection if you tried it like I tested in this document <a href="https://medium.com/@jari.p.hiltunen/first-attempt-at-integrating-mistral-models-into-open-webui-challenges-and-lessons-learned-61b4a377d3d6" data-href="https://medium.com/@jari.p.hiltunen/first-attempt-at-integrating-mistral-models-into-open-webui-challenges-and-lessons-learned-61b4a377d3d6" class="markup--anchor markup--p-anchor" target="_blank">First Attempt at Integrating Mistral Models into Open WebUI: Challenges and Lessons Learned</a>.</p><p name="0f09" id="0f09" class="graf graf--p graf-after--p">Then create a new Function from Settings — Admin Settings — Functions, name it like Mistral Manifold and copy following code:</p><pre data-code-block-mode="2" spellcheck="false" data-code-block-lang="python" name="50cf" id="50cf" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-string">&quot;&quot;&quot;<br />Draft Function for OpenWebUi<br /><br />title: Mistral Manifold Pipe<br />author: Jari Hiltunen / Divergentti https://github.com/divergentti<br />modified from Anthropic function done by author_url: https://github.com/justinh-rahb<br />version: 0.0.4 (20.01.2025) - not continuing to develop further<br />required_open_webui_version: 0.3.17<br />license: MIT<br /><br />Function lists all models at Mistral.ai and adds them to Models-selection and then tries to filter those<br />which are multiple times with different versions. This seems to be too complex approach. Define your own models<br />to the list as you like.<br /><br />If you are using free API, you can use mistral-nemo, mistral-Pixtral and Codestral Mamba.<br />The free tier at Mistral AI allows for 100 requests per hour, which translates to approximately 1.67 requests<br />per minute or around 0.027 requests per second. To stay within the rate limit, you should adjust your rate<br />limit interval accordingly.<br /><br />Before using, create your free API-keys at https://console.mistral.ai/<br />After installing this Function, add your API-key to the Valves of the Function (gear rightmost)<br /><br />Note! Image creation is not tested<br />&quot;&quot;&quot;</span><br /><br /><span class="hljs-keyword">import</span> os<br /><span class="hljs-keyword">import</span> requests<br /><span class="hljs-keyword">import</span> json<br /><span class="hljs-keyword">import</span> time<br /><span class="hljs-keyword">from</span> typing <span class="hljs-keyword">import</span> <span class="hljs-type">List</span>, <span class="hljs-type">Union</span>, Generator, Iterator<br /><span class="hljs-keyword">from</span> pydantic <span class="hljs-keyword">import</span> BaseModel, Field<br /><span class="hljs-keyword">from</span> open_webui.utils.misc <span class="hljs-keyword">import</span> pop_system_message<br /><br /><span class="hljs-keyword">class</span> <span class="hljs-title class_">Pipe</span>:<br />    <span class="hljs-keyword">class</span> <span class="hljs-title class_">Valves</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):<br />        MISTRAL_API_KEY: <span class="hljs-built_in">str</span> = Field(default=<span class="hljs-string">&quot;&quot;</span>)<br /><br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br />        self.debug_models = <span class="hljs-literal">False</span><br />        self.debug_stream = <span class="hljs-literal">True</span><br />        self.debug_errors = <span class="hljs-literal">True</span><br />        self.<span class="hljs-built_in">type</span> = <span class="hljs-string">&quot;manifold&quot;</span><br />        self.<span class="hljs-built_in">id</span> = <span class="hljs-string">&quot;mistral&quot;</span><br />        self.name = <span class="hljs-string">&quot;mistral/&quot;</span><br />        <span class="hljs-comment"># European server</span><br />        self.server= <span class="hljs-string">&quot;https://api.mistral.ai&quot;</span><br />        self.models_url = self.server + <span class="hljs-string">&quot;/v1/models&quot;</span><br />        self.chat_url = self.server + <span class="hljs-string">&quot;/v1/chat/completions&quot;</span><br />        self.temperature = <span class="hljs-number">0.7</span><br />        self.top_p = <span class="hljs-number">0.9</span><br />        self.max_tokens = <span class="hljs-number">4096</span><br />        api_key = os.getenv(<span class="hljs-string">&quot;MISTRAL_API_KEY&quot;</span>, <span class="hljs-string">&quot;&quot;</span>).strip()<br />        self.valves = self.Valves(MISTRAL_API_KEY=api_key)<br />        self.last_request_time: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.0</span>  <span class="hljs-comment"># Initialize the last request time for rate limiting</span><br />        self.rate_limit_reset: <span class="hljs-built_in">float</span> = <span class="hljs-number">0.0</span>  <span class="hljs-comment"># Initialize rate_limit_reset to 0</span><br />        self.rate_limit_interval: <span class="hljs-built_in">float</span> = <span class="hljs-number">30.0</span>  <span class="hljs-comment"># Set the rate limit interval in seconds (Open is 100 request per hour)</span><br />        self.models = <span class="hljs-string">&quot;&quot;</span><br /><br />        <span class="hljs-comment"># Not yet implemented!</span><br />        self.MAX_IMAGE_SIZE = <span class="hljs-number">5</span> * <span class="hljs-number">1024</span> * <span class="hljs-number">1024</span>  <span class="hljs-comment"># 5MB per image</span><br />        self.image_url = <span class="hljs-string">&quot;&quot;</span><br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">get_mistral_models</span>(<span class="hljs-params">self</span>):<br />        <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> self.valves.MISTRAL_API_KEY:<br />            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;MISTRAL_API_KEY is missing or invalid.&quot;</span>)<br />        headers = {<br />            <span class="hljs-string">&quot;Authorization&quot;</span>: <span class="hljs-string">f&quot;Bearer <span class="hljs-subst">{self.valves.MISTRAL_API_KEY}</span>&quot;</span>,<br />            <span class="hljs-string">&quot;Content-Type&quot;</span>: <span class="hljs-string">&quot;application/json&quot;</span>,<br />        }<br />        <span class="hljs-keyword">try</span>:<br />            response = requests.get(<span class="hljs-string">f&quot;<span class="hljs-subst">{self.models_url}</span>&quot;</span>, headers=headers)<br />            response.raise_for_status()<br />            self.models = response.json()[<span class="hljs-string">&quot;data&quot;</span>]<br />        <span class="hljs-keyword">except</span> requests.exceptions.RequestException <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_errors:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;API call failed: <span class="hljs-subst">{e}</span>&quot;</span>)<br /><br />        <span class="hljs-comment"># Map to track unique models</span><br />        model_map = {}<br />        <span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> self.models:<br />            <span class="hljs-comment"># Check if the model has the `completion_chat` capability</span><br />            <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> model[<span class="hljs-string">&quot;capabilities&quot;</span>].get(<span class="hljs-string">&quot;completion_chat&quot;</span>, <span class="hljs-literal">False</span>):<br />                <span class="hljs-keyword">continue</span><br /><br />            <span class="hljs-comment"># Extract base ID and check if it&#x27;s a &quot;latest&quot; version</span><br />            base_id = <span class="hljs-string">&quot;-&quot;</span>.join(model[<span class="hljs-string">&quot;id&quot;</span>].split(<span class="hljs-string">&quot;-&quot;</span>)[:-<span class="hljs-number">1</span>])<br />            is_latest = <span class="hljs-string">&quot;latest&quot;</span> <span class="hljs-keyword">in</span> model[<span class="hljs-string">&quot;id&quot;</span>] <span class="hljs-keyword">or</span> <span class="hljs-string">&quot;latest&quot;</span> <span class="hljs-keyword">in</span> model[<span class="hljs-string">&quot;aliases&quot;</span>]<br /><br />            <span class="hljs-comment"># Update or add model to the map</span><br />            <span class="hljs-keyword">if</span> base_id <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> model_map <span class="hljs-keyword">or</span> is_latest:<br />                model_map[base_id] = model<br /><br />        <span class="hljs-comment"># Prepare the final list of unique models</span><br />        unique_models = []<br />        <span class="hljs-keyword">for</span> base_id, model <span class="hljs-keyword">in</span> model_map.items():<br />            unique_models.append({<br />                <span class="hljs-string">&quot;id&quot;</span>: model[<span class="hljs-string">&quot;id&quot;</span>],<br />                <span class="hljs-string">&quot;name&quot;</span>: model[<span class="hljs-string">&quot;name&quot;</span>],<br />                <span class="hljs-string">&quot;capabilities&quot;</span>: model[<span class="hljs-string">&quot;capabilities&quot;</span>],<br />                <span class="hljs-string">&quot;description&quot;</span>: model[<span class="hljs-string">&quot;description&quot;</span>],<br />                <span class="hljs-string">&quot;max_context_length&quot;</span>: model[<span class="hljs-string">&quot;max_context_length&quot;</span>],<br />                <span class="hljs-string">&quot;aliases&quot;</span>: model[<span class="hljs-string">&quot;aliases&quot;</span>],<br />                <span class="hljs-string">&quot;deprecation&quot;</span>: model[<span class="hljs-string">&quot;deprecation&quot;</span>],<br />                <span class="hljs-string">&quot;default_model_temperature&quot;</span>: model[<span class="hljs-string">&quot;default_model_temperature&quot;</span>],<br />                <span class="hljs-string">&quot;type&quot;</span>: model[<span class="hljs-string">&quot;type&quot;</span>],<br />            })<br /><br />        <span class="hljs-keyword">if</span> self.debug_models:<br />            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Unique Models:&quot;</span>)<br />            <span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> unique_models:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;ID: <span class="hljs-subst">{model[<span class="hljs-string">&#x27;id&#x27;</span>]}</span>&quot;</span>)<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Name: <span class="hljs-subst">{model[<span class="hljs-string">&#x27;name&#x27;</span>]}</span>&quot;</span>)<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Capabilities: <span class="hljs-subst">{model[<span class="hljs-string">&#x27;capabilities&#x27;</span>]}</span>&quot;</span>)<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Description: <span class="hljs-subst">{model[<span class="hljs-string">&#x27;description&#x27;</span>]}</span>&quot;</span>)<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Max Context Length: <span class="hljs-subst">{model[<span class="hljs-string">&#x27;max_context_length&#x27;</span>]}</span>&quot;</span>)<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Aliases: <span class="hljs-subst">{model[<span class="hljs-string">&#x27;aliases&#x27;</span>]}</span>&quot;</span>)<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Deprecation: <span class="hljs-subst">{model[<span class="hljs-string">&#x27;deprecation&#x27;</span>]}</span>&quot;</span>)<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Default Model Temperature: <span class="hljs-subst">{model[<span class="hljs-string">&#x27;default_model_temperature&#x27;</span>]}</span>&quot;</span>)<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Type: <span class="hljs-subst">{model[<span class="hljs-string">&#x27;type&#x27;</span>]}</span>&quot;</span>)<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;-&quot;</span> * <span class="hljs-number">40</span>)<br /><br />        <span class="hljs-keyword">return</span> unique_models<br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">pipes</span>(<span class="hljs-params">self</span>) -&gt; <span class="hljs-type">List</span>[<span class="hljs-built_in">dict</span>]:<br />        <span class="hljs-comment"># This initiates the sub, but for some reason object (self) values are not passed further</span><br />        <span class="hljs-keyword">try</span>:<br />            models = self.get_mistral_models()<br />            <span class="hljs-keyword">return</span> [{<span class="hljs-string">&quot;id&quot;</span>: model[<span class="hljs-string">&quot;id&quot;</span>], <span class="hljs-string">&quot;name&quot;</span>: model[<span class="hljs-string">&quot;name&quot;</span>]} <span class="hljs-keyword">for</span> model <span class="hljs-keyword">in</span> models]<br />        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_errors:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Error fetching models: <span class="hljs-subst">{e}</span>&quot;</span>)<br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">process_image</span>(<span class="hljs-params">self, image_data</span>):<br />        <span class="hljs-keyword">if</span> image_data[<span class="hljs-string">&quot;type&quot;</span>] == <span class="hljs-string">&quot;image_url&quot;</span>:<br />            url = image_data[<span class="hljs-string">&quot;url&quot;</span>]<br />            response = requests.head(url, allow_redirects=<span class="hljs-literal">True</span>)<br />            content_length = <span class="hljs-built_in">int</span>(response.headers.get(<span class="hljs-string">&quot;content-length&quot;</span>, <span class="hljs-number">0</span>))<br />            <span class="hljs-keyword">if</span> content_length &gt; self.MAX_IMAGE_SIZE:<br />                <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;Image at URL exceeds <span class="hljs-subst">{self.MAX_IMAGE_SIZE / (<span class="hljs-number">1024</span> * <span class="hljs-number">1024</span>):<span class="hljs-number">.2</span>f}</span>MB limit&quot;</span>)<br />            <span class="hljs-keyword">return</span> {<br />                <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;image_url&quot;</span>,<br />                <span class="hljs-string">&quot;url&quot;</span>: url,<br />            }<br />        <span class="hljs-keyword">elif</span> image_data[<span class="hljs-string">&quot;type&quot;</span>] == <span class="hljs-string">&quot;image_base64&quot;</span>:<br />            mime_type, base64_data = image_data[<span class="hljs-string">&quot;data&quot;</span>].split(<span class="hljs-string">&quot;,&quot;</span>, <span class="hljs-number">1</span>)<br />            media_type = mime_type.split(<span class="hljs-string">&quot;:&quot;</span>)[<span class="hljs-number">1</span>].split(<span class="hljs-string">&quot;;&quot;</span>)[<span class="hljs-number">0</span>]<br />            image_size = <span class="hljs-built_in">len</span>(base64_data) * <span class="hljs-number">3</span> / <span class="hljs-number">4</span>  <span class="hljs-comment"># Convert base64 size to bytes</span><br />            <span class="hljs-keyword">if</span> image_size &gt; self.MAX_IMAGE_SIZE:<br />                <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">f&quot;Image size exceeds <span class="hljs-subst">{self.MAX_IMAGE_SIZE / (<span class="hljs-number">1024</span> * <span class="hljs-number">1024</span>):<span class="hljs-number">.2</span>f}</span>MB limit&quot;</span>)<br />            <span class="hljs-keyword">return</span> {<br />                <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;image_base64&quot;</span>,<br />                <span class="hljs-string">&quot;media_type&quot;</span>: media_type,<br />                <span class="hljs-string">&quot;data&quot;</span>: base64_data,<br />            }<br />        <span class="hljs-keyword">elif</span> image_data[<span class="hljs-string">&quot;type&quot;</span>] == <span class="hljs-string">&quot;image_generate&quot;</span>:<br />            prompt = image_data[<span class="hljs-string">&quot;prompt&quot;</span>]<br />            headers = {<br />                <span class="hljs-string">&quot;Authorization&quot;</span>: <span class="hljs-string">f&quot;Bearer <span class="hljs-subst">{self.valves.MISTRAL_API_KEY}</span>&quot;</span>,<br />                <span class="hljs-string">&quot;Content-Type&quot;</span>: <span class="hljs-string">&quot;application/json&quot;</span>,<br />            }<br />            payload = {<br />                <span class="hljs-string">&quot;prompt&quot;</span>: prompt,<br />                <span class="hljs-string">&quot;n_iter&quot;</span>: <span class="hljs-number">1</span>,<br />                <span class="hljs-string">&quot;size&quot;</span>: <span class="hljs-string">&quot;256x256&quot;</span>,<br />            }<br />            <span class="hljs-keyword">try</span>:<br />                response = requests.post(self.image_url, headers=headers, json=payload, timeout=(<span class="hljs-number">3.05</span>, <span class="hljs-number">60</span>))<br />                response.raise_for_status()<br />                <span class="hljs-comment"># Check rate limit headers</span><br />                rate_limit_remaining = <span class="hljs-built_in">int</span>(response.headers.get(<span class="hljs-string">&quot;X-RateLimit-Remaining&quot;</span>, <span class="hljs-number">0</span>))<br />                rate_limit_reset = <span class="hljs-built_in">int</span>(response.headers.get(<span class="hljs-string">&quot;X-RateLimit-Reset&quot;</span>, <span class="hljs-number">0</span>))<br />                self.rate_limit_reset = rate_limit_reset<br />                <span class="hljs-keyword">if</span> rate_limit_remaining == <span class="hljs-number">0</span>:<br />                    sleep_time: <span class="hljs-built_in">float</span> = <span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">float</span>(self.rate_limit_reset) - time.time())<br />                    <span class="hljs-keyword">if</span> self.debug_stream:<br />                        <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Rate limit exceeded. Sleeping for <span class="hljs-subst">{sleep_time:<span class="hljs-number">.2</span>f}</span> seconds.&quot;</span>)<br />                    time.sleep(sleep_time)  <span class="hljs-comment"># Note! This is not async method!</span><br /><br />                image_data = response.json()[<span class="hljs-string">&quot;data&quot;</span>][<span class="hljs-number">0</span>]<br />                image_url = image_data[<span class="hljs-string">&quot;url&quot;</span>]<br />                <span class="hljs-keyword">return</span> {<br />                    <span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;image_generate&quot;</span>,<br />                    <span class="hljs-string">&quot;url&quot;</span>: image_url,<br />                }<br />            <span class="hljs-keyword">except</span> requests.exceptions.RequestException <span class="hljs-keyword">as</span> e:<br />                <span class="hljs-keyword">if</span> self.debug_stream:<br />                    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Image generation failed: <span class="hljs-subst">{e}</span>&quot;</span>)<br />                <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Image generation failed&quot;</span>)<br />            <span class="hljs-keyword">except</span> requests.exceptions.RequestException <span class="hljs-keyword">as</span> e:<br />                <span class="hljs-keyword">if</span> self.debug_stream:<br />                    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Rate limit header error: <span class="hljs-subst">{e}</span>&quot;</span>)<br /><br />        <span class="hljs-keyword">else</span>:<br />            <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;Unsupported image type&quot;</span>)<br /><br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">pipe</span>(<span class="hljs-params">self, body: <span class="hljs-built_in">dict</span></span>) -&gt; <span class="hljs-type">Union</span>[<span class="hljs-built_in">str</span>, Generator, Iterator]:<br />        system_message, messages = pop_system_message(body[<span class="hljs-string">&quot;messages&quot;</span>])<br /><br />        processed_messages = []<br />        total_image_size = <span class="hljs-number">0</span><br /><br />        <span class="hljs-keyword">for</span> message <span class="hljs-keyword">in</span> messages:<br />            processed_content = []<br />            <span class="hljs-keyword">if</span> <span class="hljs-built_in">isinstance</span>(message.get(<span class="hljs-string">&quot;content&quot;</span>), <span class="hljs-built_in">list</span>):<br />                <span class="hljs-keyword">for</span> item <span class="hljs-keyword">in</span> message[<span class="hljs-string">&quot;content&quot;</span>]:<br />                    <span class="hljs-keyword">if</span> item[<span class="hljs-string">&quot;type&quot;</span>] == <span class="hljs-string">&quot;text&quot;</span>:<br />                        processed_content.append({<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: item[<span class="hljs-string">&quot;text&quot;</span>]})<br />                    <span class="hljs-keyword">elif</span> item[<span class="hljs-string">&quot;type&quot;</span>] == <span class="hljs-string">&quot;image_url&quot;</span>:<br />                        processed_image = self.process_image(item)<br />                        processed_content.append(processed_image)<br /><br />                        <span class="hljs-comment"># Track total size for base64 images</span><br />                        <span class="hljs-keyword">if</span> processed_image[<span class="hljs-string">&quot;source&quot;</span>][<span class="hljs-string">&quot;type&quot;</span>] == <span class="hljs-string">&quot;base64&quot;</span>:<br />                            image_size = <span class="hljs-built_in">len</span>(processed_image[<span class="hljs-string">&quot;source&quot;</span>][<span class="hljs-string">&quot;data&quot;</span>]) * <span class="hljs-number">3</span> / <span class="hljs-number">4</span><br />                            total_image_size += image_size<br />                            <span class="hljs-keyword">if</span> (<br />                                total_image_size &gt; <span class="hljs-number">100</span> * <span class="hljs-number">1024</span> * <span class="hljs-number">1024</span><br />                            ):  <span class="hljs-comment"># 100MB total limit</span><br />                                <span class="hljs-keyword">raise</span> ValueError(<br />                                    <span class="hljs-string">&quot;Total size of images exceeds 100 MB limit&quot;</span><br />                                )<br />            <span class="hljs-keyword">else</span>:<br />                processed_content = [<br />                    {<span class="hljs-string">&quot;type&quot;</span>: <span class="hljs-string">&quot;text&quot;</span>, <span class="hljs-string">&quot;text&quot;</span>: message.get(<span class="hljs-string">&quot;content&quot;</span>, <span class="hljs-string">&quot;&quot;</span>)}<br />                ]<br /><br />            processed_messages.append(<br />                {<span class="hljs-string">&quot;role&quot;</span>: message[<span class="hljs-string">&quot;role&quot;</span>], <span class="hljs-string">&quot;content&quot;</span>: processed_content}<br />            )<br /><br />        <span class="hljs-comment"># payload is defined as it is at mistral.ai website</span><br />        payload = {<br />            <span class="hljs-string">&quot;model&quot;</span>: body[<span class="hljs-string">&quot;model&quot;</span>][body[<span class="hljs-string">&quot;model&quot;</span>].find(<span class="hljs-string">&quot;.&quot;</span>) + <span class="hljs-number">1</span> :],<br />            <span class="hljs-string">&quot;temperature&quot;</span>: body.get(<span class="hljs-string">&quot;temperature&quot;</span>, self.temperature),<br />            <span class="hljs-string">&quot;top_p&quot;</span>: body.get(<span class="hljs-string">&quot;top_p&quot;</span>, self.top_p),<br />            <span class="hljs-string">&quot;max_tokens&quot;</span>: body.get(<span class="hljs-string">&quot;max_tokens&quot;</span>, self.max_tokens),<br />            <span class="hljs-string">&quot;stream&quot;</span>: body.get(<span class="hljs-string">&quot;stream&quot;</span>, <span class="hljs-literal">False</span>),<br />            <span class="hljs-string">&quot;messages&quot;</span>: processed_messages,<br />        }<br /><br />        headers = {<br />            <span class="hljs-string">&quot;Authorization&quot;</span>: <span class="hljs-string">f&quot;Bearer <span class="hljs-subst">{self.valves.MISTRAL_API_KEY}</span>&quot;</span>,<br />            <span class="hljs-string">&quot;mistral-version&quot;</span>: <span class="hljs-string">&quot;2025-01-01&quot;</span>,<br />            <span class="hljs-string">&quot;Content-Type&quot;</span>: <span class="hljs-string">&quot;application/json&quot;</span>,<br />        }<br /><br />        <span class="hljs-keyword">if</span> self.debug_stream:<br />            <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Headers being sent   :&quot;</span>, headers)<br /><br />        <span class="hljs-comment"># Rate limiting</span><br />        current_time = time.time()<br />        elapsed_time: <span class="hljs-built_in">float</span> = current_time - self.last_request_time<br />        <span class="hljs-keyword">if</span> elapsed_time &lt; self.rate_limit_interval:<br />            sleep_time: <span class="hljs-built_in">float</span> = <span class="hljs-built_in">max</span>(<span class="hljs-number">0.0</span>, <span class="hljs-built_in">float</span>(self.rate_limit_reset) - time.time())<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Rate limit exceeded. Sleeping for <span class="hljs-subst">{sleep_time:<span class="hljs-number">.2</span>f}</span> seconds.&quot;</span>)<br />            time.sleep(sleep_time)<br />        self.last_request_time = time.time()<br /><br />        <span class="hljs-keyword">try</span>:<br />            <span class="hljs-keyword">if</span> body.get(<span class="hljs-string">&quot;stream&quot;</span>, <span class="hljs-literal">False</span>):<br />                <span class="hljs-keyword">return</span> self.stream_response(self.chat_url, headers, payload)<br />            <span class="hljs-keyword">else</span>:<br />                <span class="hljs-keyword">return</span> self.non_stream_response(self.chat_url, headers, payload)<br />        <span class="hljs-keyword">except</span> requests.exceptions.RequestException <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Request failed: <span class="hljs-subst">{e}</span>&quot;</span>)<br />            <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;Error: Request failed: <span class="hljs-subst">{e}</span>&quot;</span><br />        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Error in pipe method: <span class="hljs-subst">{e}</span>&quot;</span>)<br />            <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;Error: <span class="hljs-subst">{e}</span>&quot;</span><br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">stream_response</span>(<span class="hljs-params">self, url, headers, payload</span>):<br />        headers[<span class="hljs-string">&quot;Authorization&quot;</span>] = <span class="hljs-string">f&quot;Bearer <span class="hljs-subst">{self.valves.MISTRAL_API_KEY}</span>&quot;</span><br />        <span class="hljs-keyword">try</span>:<br />            <span class="hljs-keyword">with</span> requests.post(<br />                url, headers=headers, json=payload, stream=<span class="hljs-literal">True</span>, timeout=(<span class="hljs-number">3.05</span>, <span class="hljs-number">60</span>)<br />            ) <span class="hljs-keyword">as</span> response:<br />                <span class="hljs-keyword">if</span> response.status_code != <span class="hljs-number">200</span>:<br />                    <span class="hljs-keyword">raise</span> Exception(<br />                        <span class="hljs-string">f&quot;HTTP Error <span class="hljs-subst">{response.status_code}</span>: <span class="hljs-subst">{response.text}</span>&quot;</span><br />                    )<br /><br /><br />                <span class="hljs-keyword">for</span> line <span class="hljs-keyword">in</span> response.iter_lines():<br />                    <span class="hljs-keyword">if</span> self.debug_stream:<br />                        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Response line: &quot;</span>, line)<br />                    <span class="hljs-keyword">if</span> line:<br />                        line = line.decode(<span class="hljs-string">&quot;utf-8&quot;</span>)<br />                        <span class="hljs-keyword">if</span> line == <span class="hljs-string">&quot;data: [DONE]&quot;</span>:<br />                            <span class="hljs-keyword">if</span> self.debug_stream:<br />                                <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Streaming completed successfully.&quot;</span>)<br />                            <span class="hljs-keyword">break</span><br />                        <span class="hljs-keyword">if</span> line.startswith(<span class="hljs-string">&quot;data: &quot;</span>):<br />                            <span class="hljs-keyword">try</span>:<br />                                data = json.loads(line[<span class="hljs-number">6</span>:])<br />                                <span class="hljs-keyword">if</span> data.get(<span class="hljs-string">&quot;choices&quot;</span>):<br />                                    <span class="hljs-keyword">for</span> choice <span class="hljs-keyword">in</span> data[<span class="hljs-string">&quot;choices&quot;</span>]:<br />                                        <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;delta&quot;</span> <span class="hljs-keyword">in</span> choice <span class="hljs-keyword">and</span> <span class="hljs-string">&quot;content&quot;</span> <span class="hljs-keyword">in</span> choice[<span class="hljs-string">&quot;delta&quot;</span>]:<br />                                            <span class="hljs-keyword">yield</span> choice[<span class="hljs-string">&quot;delta&quot;</span>][<span class="hljs-string">&quot;content&quot;</span>]<br />                                        <span class="hljs-keyword">elif</span> <span class="hljs-string">&quot;finish_reason&quot;</span> <span class="hljs-keyword">in</span> choice <span class="hljs-keyword">and</span> choice[<span class="hljs-string">&quot;finish_reason&quot;</span>] == <span class="hljs-string">&quot;stop&quot;</span>:<br />                                            <span class="hljs-keyword">break</span><br /><br />                                time.sleep(<br />                                    <span class="hljs-number">0.01</span><br />                                )  <span class="hljs-comment"># Delay to avoid overwhelming the client</span><br /><br />                            <span class="hljs-keyword">except</span> json.JSONDecodeError:<br />                                <span class="hljs-keyword">if</span> self.debug_stream:<br />                                    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Failed to parse JSON: <span class="hljs-subst">{line}</span>&quot;</span>)<br />                            <span class="hljs-keyword">except</span> KeyError <span class="hljs-keyword">as</span> e:<br />                                <span class="hljs-keyword">if</span> self.debug_stream:<br />                                    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Unexpected data structure: <span class="hljs-subst">{e}</span>&quot;</span>)<br />                                    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Full data: <span class="hljs-subst">{data}</span>&quot;</span>)<br />        <span class="hljs-keyword">except</span> requests.exceptions.RequestException <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Request failed: <span class="hljs-subst">{e}</span>&quot;</span>)<br />            <span class="hljs-keyword">yield</span> <span class="hljs-string">f&quot;Error: Request failed: <span class="hljs-subst">{e}</span>&quot;</span><br />        <span class="hljs-keyword">except</span> Exception <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;General error in stream_response method: <span class="hljs-subst">{e}</span>&quot;</span>)<br />            <span class="hljs-keyword">yield</span> <span class="hljs-string">f&quot;Error: <span class="hljs-subst">{e}</span>&quot;</span><br /><br />    <span class="hljs-keyword">def</span> <span class="hljs-title function_">non_stream_response</span>(<span class="hljs-params">self, url, headers, payload</span>):<br />        headers[<span class="hljs-string">&quot;Authorization&quot;</span>] = <span class="hljs-string">f&quot;Bearer <span class="hljs-subst">{self.valves.MISTRAL_API_KEY}</span>&quot;</span><br />        <span class="hljs-keyword">try</span>:<br />            response = requests.post(<br />                url, headers=headers, json=payload, timeout=(<span class="hljs-number">3.05</span>, <span class="hljs-number">60</span>)<br />            )<br />            <span class="hljs-keyword">if</span> response.status_code != <span class="hljs-number">200</span>:<br />                <span class="hljs-keyword">raise</span> Exception(<span class="hljs-string">f&quot;HTTP Error <span class="hljs-subst">{response.status_code}</span>: <span class="hljs-subst">{response.text}</span>&quot;</span>)<br /><br />            res = response.json()<br />            <span class="hljs-keyword">return</span> (<br />                res[<span class="hljs-string">&quot;choices&quot;</span>][<span class="hljs-number">0</span>][<span class="hljs-string">&quot;message&quot;</span>][<span class="hljs-string">&quot;content&quot;</span>] <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;choices&quot;</span> <span class="hljs-keyword">in</span> res <span class="hljs-keyword">and</span> res[<span class="hljs-string">&quot;choices&quot;</span>] <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;&quot;</span><br />            )<br />        <span class="hljs-keyword">except</span> requests.exceptions.RequestException <span class="hljs-keyword">as</span> e:<br />            <span class="hljs-keyword">if</span> self.debug_stream:<br />                <span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Failed non-stream request: <span class="hljs-subst">{e}</span>&quot;</span>)<br />            <span class="hljs-keyword">return</span> <span class="hljs-string">f&quot;Error: <span class="hljs-subst">{e}</span>&quot;</span></span></pre><p name="46ce" id="46ce" class="graf graf--p graf-after--pre">Then add your Mistral API-key to the Valve of the Function you just created:</p><figure name="b4f9" id="b4f9" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*RJOER3TH9jKqqU-ieVFk2g.png" data-width="914" data-height="384" src="https://cdn-images-1.medium.com/max/800/1*RJOER3TH9jKqqU-ieVFk2g.png"><figcaption class="imageCaption">Entering the API-key for the Function</figcaption></figure><p name="79c6" id="79c6" class="graf graf--p graf-after--figure graf--trailing">Note! I have not tested pixtral part at all, my goals was to get chat completion working.</p></div></div></section><section name="6a9a" class="section section--body section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><p name="9a3a" id="9a3a" class="graf graf--p graf--leading">If you like to develop this further, set self.debug-options to True and look at the backend’s screen. If you have set self.debug_stream = True, you should see headers sent to Mistral API:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="bash" name="2184" id="2184" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">Headers being sent   : {<span class="hljs-string">&#x27;Authorization&#x27;</span>: <span class="hljs-string">&#x27;Bearer your API Key&#x27;</span>, <span class="hljs-string">&#x27;mistral-version&#x27;</span>: <span class="hljs-string">&#x27;2025-01-01&#x27;</span>, <span class="hljs-string">&#x27;Content-Type&#x27;</span>: <span class="hljs-string">&#x27;application/json&#x27;</span>}</span></pre><p name="fc7c" id="fc7c" class="graf graf--p graf-after--pre">And with self.debug_stream = True you should see responses from the Mistral.ai with a stream information and for example how many tokens you consumed:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="rust" name="6353" id="6353" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">Response line:  b<span class="hljs-symbol">&#x27;data</span>: {<span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-string">&quot;6ba19aa1faf84bce981f38d365ac21a6&quot;</span>,<br /><span class="hljs-string">&quot;object&quot;</span>:<span class="hljs-string">&quot;chat.completion.chunk&quot;</span>,<span class="hljs-string">&quot;created&quot;</span>:<span class="hljs-number">1737360524</span>,<br /><span class="hljs-string">&quot;model&quot;</span>:<span class="hljs-string">&quot;open-mistral-nemo-2407&quot;</span>,<span class="hljs-string">&quot;choices&quot;</span>:<br />[{<span class="hljs-string">&quot;index&quot;</span>:<span class="hljs-number">0</span>,<span class="hljs-string">&quot;delta&quot;</span>:{<span class="hljs-string">&quot;content&quot;</span>:<span class="hljs-string">&quot; attention&quot;</span>},<span class="hljs-string">&quot;finish_reason&quot;</span>:null}]}&#x27;<br />Response line:  b&#x27;&#x27;<br />Response line:  b<span class="hljs-symbol">&#x27;data</span>: {<span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-string">&quot;6ba19aa1faf84bce981f38d365ac21a6&quot;</span>,<br /><span class="hljs-string">&quot;object&quot;</span>:<span class="hljs-string">&quot;chat.completion.chunk&quot;</span>,<span class="hljs-string">&quot;created&quot;</span>:<span class="hljs-number">1737360524</span>,<br /><span class="hljs-string">&quot;model&quot;</span>:<span class="hljs-string">&quot;open-mistral-nemo-2407&quot;</span>,<span class="hljs-string">&quot;choices&quot;</span>:<br />[{<span class="hljs-string">&quot;index&quot;</span>:<span class="hljs-number">0</span>,<span class="hljs-string">&quot;delta&quot;</span>:{<span class="hljs-string">&quot;content&quot;</span>:<span class="hljs-string">&quot;.&quot;</span>},<span class="hljs-string">&quot;finish_reason&quot;</span>:null}]}&#x27;<br />Response line:  b&#x27;&#x27;<br />Response line:  b<span class="hljs-symbol">&#x27;data</span>: {<span class="hljs-string">&quot;id&quot;</span>:<span class="hljs-string">&quot;6ba19aa1faf84bce981f38d365ac21a6&quot;</span>,<br /><span class="hljs-string">&quot;object&quot;</span>:<span class="hljs-string">&quot;chat.completion.chunk&quot;</span>,<span class="hljs-string">&quot;created&quot;</span>:<span class="hljs-number">1737360524</span>,<br /><span class="hljs-string">&quot;model&quot;</span>:<span class="hljs-string">&quot;open-mistral-nemo-2407&quot;</span>,<span class="hljs-string">&quot;choices&quot;</span>:<br />[{<span class="hljs-string">&quot;index&quot;</span>:<span class="hljs-number">0</span>,<span class="hljs-string">&quot;delta&quot;</span>:{<span class="hljs-string">&quot;content&quot;</span>:<span class="hljs-string">&quot;&quot;</span>},<br /><span class="hljs-string">&quot;finish_reason&quot;</span>:<span class="hljs-string">&quot;stop&quot;</span>}],<span class="hljs-string">&quot;usage&quot;</span>:<br />{<span class="hljs-string">&quot;prompt_tokens&quot;</span>:<span class="hljs-number">7173</span>,<span class="hljs-string">&quot;total_tokens&quot;</span>:<span class="hljs-number">7268</span>,<span class="hljs-string">&quot;completion_tokens&quot;</span>:<span class="hljs-number">95</span>}}&#x27;<br />Response line:  b&#x27;&#x27;<br />Response line:  b<span class="hljs-symbol">&#x27;data</span>: [DONE]&#x27;<br />Streaming completed successfully.<br />INFO:     <span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">45280</span> - <span class="hljs-string">&quot;POST /api/chat/completed HTTP/1.1&quot;</span> <span class="hljs-number">200</span> OK<br />INFO:     <span class="hljs-number">127.0</span>.<span class="hljs-number">0.1</span>:<span class="hljs-number">45280</span> - <span class="hljs-string">&quot;POST /api/v1/chats/xxxx-f247-4885-bb14-0f93e22af7a4 HTTP/1.1&quot;</span> <span class="hljs-number">200</span> OK</span></pre><p name="7441" id="7441" class="graf graf--p graf-after--pre">If you have set self.debug_models = True, you should see list of models and their capabilities and then develop code so that for each model you have different streams or payloads (this is one example):</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="yaml" name="4c4d" id="4c4d" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content"><span class="hljs-attr">ID:</span> <span class="hljs-string">open-mistral-nemo-2407</span><br /><span class="hljs-attr">Name:</span> <span class="hljs-string">open-mistral-nemo</span><br /><span class="hljs-attr">Capabilities:</span> {<span class="hljs-attr">&#x27;completion_chat&#x27;:</span> <span class="hljs-literal">True</span>, <span class="hljs-attr">&#x27;completion_fim&#x27;:</span> <span class="hljs-literal">False</span>, <span class="hljs-attr">&#x27;function_calling&#x27;:</span> <span class="hljs-literal">True</span>, <span class="hljs-attr">&#x27;fine_tuning&#x27;:</span> <span class="hljs-literal">True</span>, <span class="hljs-attr">&#x27;vision&#x27;:</span> <span class="hljs-literal">False</span>}<br /><span class="hljs-attr">Description:</span> <span class="hljs-string">Official</span> <span class="hljs-string">open-mistral-nemo</span> <span class="hljs-string">Mistral</span> <span class="hljs-string">AI</span> <span class="hljs-string">model</span><br /><span class="hljs-attr">Max Context Length:</span> <span class="hljs-number">131072</span><br /><span class="hljs-attr">Aliases:</span> [<span class="hljs-string">&#x27;open-mistral-nemo&#x27;</span>, <span class="hljs-string">&#x27;mistral-tiny-2407&#x27;</span>, <span class="hljs-string">&#x27;mistral-tiny-latest&#x27;</span>]<br /><span class="hljs-attr">Deprecation:</span> <span class="hljs-string">None</span><br /><span class="hljs-attr">Default Model Temperature:</span> <span class="hljs-number">0.3</span><br /><span class="hljs-attr">Type:</span> <span class="hljs-string">base</span></span></pre><p name="07cf" id="07cf" class="graf graf--p graf-after--pre">With debug_errors = True you will see errors related to other parts of the code.</p><p name="c901" id="c901" class="graf graf--p graf-after--p">Note! Timers are not asynchronous, which means, that OI will pause totally during sleep etc. Better approach will be using asynchronous code.</p><p name="cc50" id="cc50" class="graf graf--p graf-after--p graf--trailing">Good luck with your testing!</p></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@jari.p.hiltunen" class="p-author h-card">Jari Hiltunen</a> on <a href="https://medium.com/p/da2ceee25e9b"><time class="dt-published" datetime="2025-01-17T12:25:31.869Z">January 17, 2025</time></a>.</p><p><a href="https://medium.com/@jari.p.hiltunen/debugging-mistral-ai-api-issue-no-solution-so-far-da2ceee25e9b" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on January 26, 2025.</p></footer></article></body></html>