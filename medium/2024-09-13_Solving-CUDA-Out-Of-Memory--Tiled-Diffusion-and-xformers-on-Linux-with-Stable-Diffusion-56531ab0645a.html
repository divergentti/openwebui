<!DOCTYPE html><html><head><meta http-equiv="Content-Type" content="text/html; charset=utf-8"><title>Solving CUDA Out Of Memory: Tiled Diffusion and xformers on Linux with Stable Diffusion</title><style>
      * {
        font-family: Georgia, Cambria, "Times New Roman", Times, serif;
      }
      html, body {
        margin: 0;
        padding: 0;
      }
      h1 {
        font-size: 50px;
        margin-bottom: 17px;
        color: #333;
      }
      h2 {
        font-size: 24px;
        line-height: 1.6;
        margin: 30px 0 0 0;
        margin-bottom: 18px;
        margin-top: 33px;
        color: #333;
      }
      h3 {
        font-size: 30px;
        margin: 10px 0 20px 0;
        color: #333;
      }
      header {
        width: 640px;
        margin: auto;
      }
      section {
        width: 640px;
        margin: auto;
      }
      section p {
        margin-bottom: 27px;
        font-size: 20px;
        line-height: 1.6;
        color: #333;
      }
      section img {
        max-width: 640px;
      }
      footer {
        padding: 0 20px;
        margin: 50px 0;
        text-align: center;
        font-size: 12px;
      }
      .aspectRatioPlaceholder {
        max-width: auto !important;
        max-height: auto !important;
      }
      .aspectRatioPlaceholder-fill {
        padding-bottom: 0 !important;
      }
      header,
      section[data-field=subtitle],
      section[data-field=description] {
        display: none;
      }
      </style></head><body><article class="h-entry">
<header>
<h1 class="p-name">Solving CUDA Out Of Memory: Tiled Diffusion and xformers on Linux with Stable Diffusion</h1>
</header>
<section data-field="subtitle" class="p-summary">
For many Linux users, the “CUDA Out Of Memory” error is a common and frustrating issue
</section>
<section data-field="body" class="e-content">
<section name="4e59" class="section section--body section--first section--last"><div class="section-divider"><hr class="section-divider"></div><div class="section-content"><div class="section-inner sectionLayout--insetColumn"><h3 name="17fb" id="17fb" class="graf graf--h3 graf--leading graf--title">Solving CUDA Out Of Memory: Tiled Diffusion and xformers on Linux with Stable Diffusion</h3><h3 name="5dab" id="5dab" class="graf graf--h3 graf-after--h3">Introduction:</h3><p name="a688" id="a688" class="graf graf--p graf-after--h3">For many Linux users, the “CUDA Out Of Memory” error is a common and frustrating issue, especially when working with resource-heavy image generators like Stable Diffusion. Fortunately, solutions such as Tiled Diffusion and xformers can help optimize memory usage and avoid VRAM limitations. In this article, which I developed together with ChatGPT, we’ll explain how these tools work, how to effectively optimize your setup, and what to do if something goes wrong during installation.</p><h3 name="cc9f" id="cc9f" class="graf graf--h3 graf-after--p">Background:</h3><h4 name="bbb7" id="bbb7" class="graf graf--h4 graf-after--h3">What is Stable Diffusion, and why is it so popular for image generation?</h4><p name="de50" id="de50" class="graf graf--p graf-after--h4">Stable Diffusion is an open-source text-to-image model developed by Stability AI that has become widely popular for generating high-quality images based on simple text prompts. One of the reasons for its popularity is the balance between image quality and the hardware requirements to run the model. Unlike some other models, Stable Diffusion can be run on consumer-grade hardware, especially GPUs with as little as 4–6GB of VRAM, making it accessible to more people. Additionally, its open-source nature allows for a vibrant community of developers and artists to create extensions, tools, and optimizations that enhance its capabilities. Users can customize the generation process, adjust parameters, and experiment with different styles, which makes it versatile for various creative and technical applications.</p><figure name="5807" id="5807" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*p5fd1qVk8pEk8mYbxLzCkQ.png" data-width="1024" data-height="1024" src="https://cdn-images-1.medium.com/max/800/1*p5fd1qVk8pEk8mYbxLzCkQ.png"></figure><h4 name="856b" id="856b" class="graf graf--h4 graf-after--figure">Memory management differences between Linux and Windows, and why the “CUDA Out Of Memory” error is so common:</h4><p name="ae2f" id="ae2f" class="graf graf--p graf-after--h4">Memory management on Linux and Windows differs significantly, especially in how the operating systems handle GPU memory. On Windows, when GPU VRAM (Video RAM) runs out, the system can “swap” memory to system RAM, allowing processes to continue, albeit with slower performance. This is known as paging, where the system uses the swap file to manage temporary data overflow. This feature is often automatic and can prevent memory errors in resource-heavy applications like Stable Diffusion.</p><p name="260b" id="260b" class="graf graf--p graf-after--p">However, on Linux, this swap mechanism for GPU memory is not as robust. When VRAM is exhausted, the operating system cannot easily offload data to system RAM, leading to immediate memory-related errors like “CUDA Out Of Memory.” This is especially problematic when working with large images or running multiple tasks that demand significant GPU resources. Linux relies heavily on efficient memory management within applications and libraries like PyTorch, which can result in more frequent memory allocation failures.</p><p name="af85" id="af85" class="graf graf--p graf-after--p">This makes GPU-heavy applications, like Stable Diffusion, prone to running out of VRAM unless additional memory management techniques are employed — such as using <code class="markup--code markup--p-code">--medvram</code> or <code class="markup--code markup--p-code">--lowvram</code> options, or employing technologies like <strong class="markup--strong markup--p-strong">xformers</strong> and <strong class="markup--strong markup--p-strong">Tiled Diffusion</strong> to optimize memory usage.</p><h4 name="c7d0" id="c7d0" class="graf graf--h4 graf-after--p">An overview of CUDA Unified Memory and why it doesn’t yet function on Linux the same way it does on Windows:</h4><p name="3662" id="3662" class="graf graf--p graf-after--h4">CUDA Unified Memory is a feature in NVIDIA’s CUDA platform designed to simplify memory management by allowing the CPU and GPU to share a unified memory space. In essence, it enables automatic migration of data between the CPU’s RAM and the GPU’s VRAM. This dynamic memory sharing can prevent GPU memory from running out by offloading less critical data to system RAM.</p><p name="19d6" id="19d6" class="graf graf--p graf-after--p">On Windows, this functionality works more smoothly because of its more mature driver support and integration with CUDA, allowing for better handling of large memory loads. However, on Linux, while CUDA Unified Memory is supported, its implementation is not as advanced. The current support for memory swapping between GPU and CPU is limited, meaning that once GPU VRAM runs out, the system cannot efficiently swap memory to the CPU’s RAM in the same way as it does on Windows.</p><p name="f2cd" id="f2cd" class="graf graf--p graf-after--p">Because of this limitation, Linux users often experience “CUDA Out Of Memory” errors when generating images in Stable Diffusion or running other GPU-intensive tasks. The ongoing development in this area by NVIDIA could lead to future improvements, but for now, tools like <strong class="markup--strong markup--p-strong">Tiled Diffusion</strong> and careful memory management remain necessary workarounds on Linux.</p><figure name="d1f0" id="d1f0" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*UTfJiFdTe3jz-9OEbLG6-w.png" data-width="2048" data-height="2048" src="https://cdn-images-1.medium.com/max/800/1*UTfJiFdTe3jz-9OEbLG6-w.png"></figure><h3 name="2f7d" id="2f7d" class="graf graf--h3 graf-after--figure">The Role of Tiled Diffusion:</h3><p name="ca23" id="ca23" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">How Tiled Diffusion works</strong>: Tiled Diffusion splits images into smaller tiles and processes them one at a time. This reduces the overall memory load on the GPU, allowing it to handle high-resolution images without running out of VRAM.</p><p name="404f" id="404f" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Advantages</strong>: By processing images in smaller chunks, Tiled Diffusion allows you to generate larger and more detailed images without encountering memory limitations. This method is especially useful for users with limited GPU memory but who still want to produce high-quality images.</p><h3 name="f4fc" id="f4fc" class="graf graf--h3 graf-after--p">The Role of xformers:</h3><p name="9bd7" id="9bd7" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">How xformers works</strong>: xformers is a library that optimizes memory usage and speeds up processing, especially for handling large images. It enables more efficient VRAM usage and can help reduce CUDA Out Of Memory errors by optimizing how memory is allocated and used during the image generation process.</p><p name="7645" id="7645" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Compatibility</strong>: When using xformers, it’s important to ensure you’re using the correct version of PyTorch and CUDA. If the versions are mismatched, you may encounter issues with performance or memory handling.</p><p name="dc53" id="dc53" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Installation tips</strong>: Proper installation of xformers is key to getting the most out of it. Ensure that the version of xformers you install matches your version of PyTorch and CUDA. If you experience issues, it’s always safe to reinstall or use Automatic1111’s installation script.</p><figure name="7b87" id="7b87" class="graf graf--figure graf-after--p"><img class="graf-image" data-image-id="1*h97w0aGBIzD54scwNdSxeA.png" data-width="1024" data-height="1024" src="https://cdn-images-1.medium.com/max/800/1*h97w0aGBIzD54scwNdSxeA.png"></figure><h3 name="2567" id="2567" class="graf graf--h3 graf-after--figure">Startup Parameters and Optimization:</h3><p name="2708" id="2708" class="graf graf--p graf-after--h3">Startup parameters like <code class="markup--code markup--p-code">--medvram</code> and <code class="markup--code markup--p-code">--lowvram</code> can help optimize VRAM usage and prevent memory overflow. These parameters reduce the amount of VRAM used by Stable Diffusion and prioritize less memory-intensive operations.</p><p name="fda5" id="fda5" class="graf graf--p graf-after--p">Examples of useful parameters:</p><ul class="postList"><li name="379a" id="379a" class="graf graf--li graf-after--p"><code class="markup--code markup--li-code">--medvram</code>: Uses less VRAM, suitable for medium-sized images.</li><li name="bc6e" id="bc6e" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">--lowvram</code>: Further reduces memory usage, ideal for lower-end GPUs.</li><li name="8fbd" id="8fbd" class="graf graf--li graf-after--li"><code class="markup--code markup--li-code">--xformers</code>: Enables xformers to optimize memory handling.</li></ul><p name="5aec" id="5aec" class="graf graf--p graf-after--li">If your setup or pip updates go wrong, you can always delete the <code class="markup--code markup--p-code">venv</code> directory and recreate it with:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="typescript" name="561e" id="561e" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">python3<span class="hljs-number">.11</span> -m venv venv</span></pre><p name="e7be" id="e7be" class="graf graf--p graf-after--pre">After this, you can let the <strong class="markup--strong markup--p-strong">Automatic1111</strong> installation script reinstall all necessary packages, including <strong class="markup--strong markup--p-strong">xformers</strong>. The good news is that all your settings and extensions will remain intact, so you can continue using your project without losing any configurations or add-ons.</p><p name="4696" id="4696" class="graf graf--p graf-after--p"><strong class="markup--strong markup--p-strong">Source</strong>: <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Optimizations" data-href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Optimizations" class="markup--anchor markup--p-anchor" rel="noopener" target="_blank">AUTOMATIC1111 Optimizations Guide</a></p><h3 name="ab47" id="ab47" class="graf graf--h3 graf-after--p">Practical Guide:</h3><h4 name="324e" id="324e" class="graf graf--h4 graf-after--h3">How to enable Tiled Diffusion and xformers in Stable Diffusion:</h4><p name="28af" id="28af" class="graf graf--p graf-after--h4">To enable <strong class="markup--strong markup--p-strong">Tiled Diffusion</strong> in Stable Diffusion, follow these steps:</p><ol class="postList"><li name="95cb" id="95cb" class="graf graf--li graf-after--p">Install the <strong class="markup--strong markup--li-strong">MultiDiffusion Upscaler</strong> extension for Automatic1111’s Web UI. This extension includes the Tiled Diffusion functionality.</li><li name="0677" id="0677" class="graf graf--li graf-after--li">You can find the installation guide and detailed instructions for <strong class="markup--strong markup--li-strong">Tiled Diffusion</strong> on the <a href="https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111/wiki/Tiled-Diffusion" data-href="https://github.com/pkuliyi2015/multidiffusion-upscaler-for-automatic1111/wiki/Tiled-Diffusion" class="markup--anchor markup--li-anchor" rel="noopener" target="_blank">MultiDiffusion Upscaler wiki</a>.</li><li name="2c0e" id="2c0e" class="graf graf--li graf-after--li">Once installed, access the Tiled Diffusion settings within the Automatic1111 Web UI and configure the tile size and overlap parameters to suit your system’s memory capacity.</li></ol><h4 name="e7b0" id="e7b0" class="graf graf--h4 graf-after--li">How to enable xformers:</h4><p name="a530" id="a530" class="graf graf--p graf-after--h4">Ensure that <strong class="markup--strong markup--p-strong">xformers</strong> is installed and compatible with your PyTorch and CUDA versions. If you encounter issues, activate your virtual environment (venv) and you can reinstall it using:</p><pre data-code-block-mode="1" spellcheck="false" data-code-block-lang="css" name="0f0d" id="0f0d" class="graf graf--pre graf-after--p graf--preV2"><span class="pre--content">pip install xformers <span class="hljs-attr">--force-reinstall</span></span></pre><p name="f369" id="f369" class="graf graf--p graf-after--pre">When launching Stable Diffusion, add the <code class="markup--code markup--p-code">--xformers</code> startup parameter to enable memory-efficient attention.</p><h4 name="5046" id="5046" class="graf graf--h4 graf-after--p">Tips for choosing the right configuration based on your GPU memory:</h4><ul class="postList"><li name="c251" id="c251" class="graf graf--li graf-after--h4">If you have a limited amount of VRAM (4–6GB), use <code class="markup--code markup--li-code">--medvram</code> or <code class="markup--code markup--li-code">--lowvram</code> to further reduce memory usage.</li><li name="77df" id="77df" class="graf graf--li graf-after--li">Adjust the <strong class="markup--strong markup--li-strong">Tiled Diffusion</strong> settings by selecting smaller tile sizes to prevent VRAM overflow.</li><li name="61be" id="61be" class="graf graf--li graf-after--li">Combine Tiled Diffusion with xformers for optimal performance in low-memory environments.</li></ul><h3 name="e354" id="e354" class="graf graf--h3 graf-after--li">Conclusion:</h3><p name="c3ad" id="c3ad" class="graf graf--p graf-after--h3"><strong class="markup--strong markup--p-strong">Tiled Diffusion</strong> and <strong class="markup--strong markup--p-strong">xformers</strong> together provide an effective way to handle memory limitations and enable smooth image generation at higher resolutions without encountering “CUDA Out Of Memory” errors.</p><p name="1cef" id="1cef" class="graf graf--p graf-after--p">Looking ahead, we can expect improvements from NVIDIA driver updates and <strong class="markup--strong markup--p-strong">CUDA Unified Memory</strong>, which will make memory management on Linux even more efficient.</p><p name="14b2" id="14b2" class="graf graf--p graf-after--p">For Automatic1111 startup so that Tiled Diffusion is enabled at start, read <a href="https://medium.com/@jari.p.hiltunen/modifying-the-ui-config-json-54bb75ed2284" data-href="https://medium.com/@jari.p.hiltunen/modifying-the-ui-config-json-54bb75ed2284" class="markup--anchor markup--p-anchor" target="_blank">Modifying the ui-config.json File in Stable Diffusion — Enabling Tiled Diffusion and SDXL Turbo Models</a></p><figure name="4d86" id="4d86" class="graf graf--figure graf-after--p graf--trailing"><img class="graf-image" data-image-id="1*XxfJ9k_zTB1vGyEqSnOIXg.png" data-width="1024" data-height="1024" data-is-featured="true" src="https://cdn-images-1.medium.com/max/800/1*XxfJ9k_zTB1vGyEqSnOIXg.png"><figcaption class="imageCaption">Prompt: “A futuristic workspace where a developer is using a high-tech computer setup to manage GPU memory while generating AI art. Multiple screens show error messages like “CUDA Out Of Memory,” along with graphs of memory usage and code with commands like <code class="markup--code markup--figure-code">--medvram</code> and <code class="markup--code markup--figure-code">--xformers</code>. In the background, a powerful GPU is visible, with glowing lights, connected to the system. On another screen, high-resolution images are being generated through Stable Diffusion, split into tiles, with coding references to Tiled Diffusion and optimizations. The scene blends technology, creativity, and problem-solving in a sleek, modern setting. <strong class="markup--strong markup--figure-strong">Style:</strong> realistic, digital art, tech-centric.”</figcaption></figure></div></div></section>
</section>
<footer><p>By <a href="https://medium.com/@jari.p.hiltunen" class="p-author h-card">Jari Hiltunen</a> on <a href="https://medium.com/p/56531ab0645a"><time class="dt-published" datetime="2024-09-13T07:35:59.389Z">September 13, 2024</time></a>.</p><p><a href="https://medium.com/@jari.p.hiltunen/solving-cuda-out-of-memory-tiled-diffusion-and-xformers-on-linux-with-stable-diffusion-56531ab0645a" class="p-canonical">Canonical link</a></p><p>Exported from <a href="https://medium.com">Medium</a> on January 26, 2025.</p></footer></article></body></html>